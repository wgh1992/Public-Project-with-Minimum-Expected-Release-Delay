{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:30:59.155135Z",
     "start_time": "2021-03-08T06:30:57.862332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:30:59.168065Z",
     "start_time": "2021-03-08T06:30:59.157096Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 7\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0\n",
    "Normal_loc2 = 1.5\n",
    "Normal_scale1 = 0.5\n",
    "Normal_scale2 = 0.5\n",
    "Distribution_number = 10000\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "order = \"twopeaknormal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:00.510075Z",
     "start_time": "2021-03-08T06:30:59.171093Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[-0.2405541   1.8693572  -0.40974569 -0.42661179  0.71932214  0.07162663\n",
      "   1.90323995]\n",
      " [-0.11172939  0.16647262 -0.06409596  1.52284171  0.59776377  1.62981898\n",
      "   0.04192414]\n",
      " [ 0.44763428 -0.8600823   1.78157347  1.23160282  2.27483763  0.63536074\n",
      "   0.30723956]]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../distribution/twopeaknormalwithoutlimit.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "# for i in range(len(value_list)):\n",
    "#     for j in range(len(value_list[0])):\n",
    "#         if (value_list[i][j] <= 0):\n",
    "#             value_list[i][j] = 0\n",
    "#         if (value_list[i][j] >= 1):\n",
    "#             value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:00.528981Z",
     "start_time": "2021-03-08T06:31:00.512026Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:01.839891Z",
     "start_time": "2021-03-08T06:31:00.532970Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6979)\n",
      "tensor(0.4320)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:01.849873Z",
     "start_time": "2021-03-08T06:31:01.840859Z"
    }
   },
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return bits*0\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(Agent_number_n).cuda() - bits\n",
    "    paymentBits = negBits*1000\n",
    "\n",
    "    \n",
    "    cost_sharing_payment = 1.0/torch.sum(bits).item()\n",
    "\n",
    "    payments = bits * cost_sharing_payment\n",
    "    payments += paymentBits\n",
    "    \n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits):\n",
    "    payments = bitsToPayments(bits)\n",
    "    \n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    \n",
    "    if torch.sum(newBits).item() == 0:\n",
    "        return newBits\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "    \n",
    "def tpToTotalDelay(tp, deadline, _i):\n",
    "    ans = tpToBits(tp, torch.ones(Agent_number_n).type(torch.uint8).cuda())\n",
    "    if(torch.sum(ans).item()==0):\n",
    "        return torch.sum((1.0 - ans) * deadline), False\n",
    "    else:\n",
    "        return torch.sum((1.0 - ans) * deadline), True\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp,torch.ones(Agent_number_n).type(torch.uint8).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:01.857819Z",
     "start_time": "2021-03-08T06:31:01.850833Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-9>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:01.876770Z",
     "start_time": "2021-03-08T06:31:01.858819Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 50\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(Agent_number_n,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, value_list):\n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        # h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)  # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        deadline = torch.sigmoid((h4 + 1)*10)\n",
    "        # deadline = torch.sigmoid(self.deadline)\n",
    "        # print(deadline)\n",
    "        # return\n",
    "\n",
    "        Possible_i_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "\n",
    "            Possible = 0\n",
    "            for k in range(len(value_list)):\n",
    "                value_tensor = value_list[k]\n",
    "                test = copy.deepcopy(value_tensor)\n",
    "                test_change = copy.deepcopy(test)\n",
    "                test_change = deadline * test_change\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "\n",
    "                judge_i = tpToTotalDelay(tp_0, deadline, i)[1]\n",
    "                \n",
    "#                 temp_max_delay_list,temp_sum_delay,judge_ii =  cost_sharing_with_deadline(tp_0,\n",
    "#                         deadline,1.0)\n",
    "#                 if (judge_i != judge_ii):\n",
    "#                     print(\"false\")\n",
    "#                     return\n",
    "                \n",
    "                \n",
    "                if (judge_i == True):\n",
    "                    Possible = Possible + 1.0/len(value_list)\n",
    "\n",
    "            Possible_i_list.append(Possible)\n",
    "\n",
    "        temp_sum_delay_total = torch.zeros(1).cuda()\n",
    "        temp_max_delay_total = torch.zeros(1).cuda()\n",
    "\n",
    "#         print(\"deadline:\",deadline)\n",
    "\n",
    "\n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            test_change = copy.deepcopy(test)\n",
    "            test_change = deadline * test_change\n",
    "\n",
    "            temp_sum_delay = 0\n",
    "            temp_max_delay = 0\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                tp_1 = test_change.clone()\n",
    "                tp_1[i] = 1\n",
    "                # tp_0 = copy.deepcopy(test_change_i)\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "                offer = tpToPayments(tp_1)[i]\n",
    "\n",
    "                Delay_1 = tpToTotalDelay(tp_1, deadline, i)[0]\n",
    "                Delay_2 = tpToTotalDelay(tp_0, deadline, i)[0]\n",
    "\n",
    "                temp = ((1.0 - cdf(offer/deadline[i], order)) * Delay_1 + cdf(\n",
    "                    offer/deadline[i], order) * Delay_2)/Agent_number_n\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "#                 print(\"test_change\",test_change)\n",
    "                \n",
    "#                 print(\"offer\",offer,cdf(offer/deadline[i], order))\n",
    "#                 print(\"temp\",temp)\n",
    "#                 print(\"Delay_1\", Delay_1)\n",
    "#                 print(\"Delay_2\", Delay_2)\n",
    "\n",
    "#                 print()\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "#             print(\"test_change\",test_change)\n",
    "#             print(\"deadline\",deadline)\n",
    "#             print(\"offer\",offer)\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "\n",
    "#             return\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                Possible = Possible_i_list[i]\n",
    "\n",
    "                temp = (1.0-deadline[i].clone()) * \\\n",
    "                    torch.tensor(1.0-Possible).cuda()\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "            temp_sum_delay_total = temp_sum_delay_total + temp_sum_delay\n",
    "            temp_sum_delay_total += torch.sum(-deadline)/1000\n",
    "\n",
    "        return temp_max_delay_total, temp_sum_delay_total, deadline.cpu(\n",
    "        ).data.numpy(), float(temp_sum_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T06:31:01.883751Z",
     "start_time": "2021-03-08T06:31:01.877769Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "#net = torch.load(\"Deep_learning_with_deadline_5\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00002)\n",
    "\n",
    "batch_size = 32\n",
    "echo = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:04.219094Z",
     "start_time": "2021-03-08T06:31:01.884749Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch_loss: 2.59 \n",
      "value: [1.58418422078453, -0.19381094746623628, 0.5009721564322255, 0.3917565883141709, 1.7735102585231686, 1.2989737434294477, 1.6311196405020345]\n",
      "deadline: [0.99995494 0.9999536  0.99998    0.99998367 0.99995863 0.9999764\n",
      " 0.999966  ]\n",
      "\n",
      "i 100\n",
      "batch_loss: 2.50 \n",
      "value: [0.27404461586018586, -0.13279744710951408, 1.5736764583999732, 1.2917528823496205, -0.8250540512498274, 1.0300541315534986, 0.4402639286654178]\n",
      "deadline: [0.9999497  0.99994934 0.9999738  0.9999796  0.9999422  0.99997103\n",
      " 0.999961  ]\n",
      "\n",
      "i 200\n",
      "batch_loss: 2.49 \n",
      "value: [-0.1455860735018783, -0.49999613841574964, 1.699722825124485, -0.45936505604101496, 0.16287667435416692, 1.7961670018364213, 0.22372918547065423]\n",
      "deadline: [0.9999472  0.9999409  0.9999639  0.9999739  0.9999151  0.99996173\n",
      " 0.99995697]\n",
      "\n",
      "i 300\n",
      "batch_loss: 2.66 \n",
      "value: [1.2473737178849955, -0.4338828805334046, 2.1294691035572866, 2.5885485443522276, -0.10010087494071447, 1.2523899302510653, 1.4019262876531189]\n",
      "deadline: [0.999948  0.9999236 0.9999455 0.9999647 0.9998492 0.9999465 0.9999529]\n",
      "\n",
      "i 400\n",
      "batch_loss: 2.21 \n",
      "value: [0.7353091557734782, 2.0567925064387995, 1.2958565217094442, 1.7918115911876642, 0.6871620010951281, 1.2539194085366732, 0.26665635158063]\n",
      "deadline: [0.99995446 0.99987376 0.99989593 0.99994516 0.999608   0.99990726\n",
      " 0.9999505 ]\n",
      "\n",
      "i 500\n",
      "batch_loss: 2.54 \n",
      "value: [0.3600172487770803, 0.34505462779801915, 2.1190598520606865, 0.06685797317844597, 0.40919151702583184, 1.877411107748245, 0.6967226220083216]\n",
      "deadline: [0.9999634  0.999718   0.99971    0.9998622  0.99788994 0.9997603\n",
      " 0.99994266]\n",
      "\n",
      "i 600\n",
      "batch_loss: 1.99 \n",
      "value: [0.08155532460727365, 0.36587749750139864, 1.339465145330249, 1.2229235640299612, 1.637464499923473, 1.9163174809049397, 0.4871840141401543]\n",
      "deadline: [0.99997616 0.99862826 0.9986461  0.9994318  0.9714415  0.998727\n",
      " 0.9999298 ]\n",
      "\n",
      "i 700\n",
      "batch_loss: 2.15 \n",
      "value: [1.7209821390532067, 1.905342550405136, 1.725517868587984, 0.21596686382028452, 1.8873580043376241, 0.3420240245696815, -0.2369200271586103]\n",
      "deadline: [0.9999871  0.97870904 0.98290586 0.99369365 0.3450598  0.9762006\n",
      " 0.9998747 ]\n",
      "\n",
      "i 800\n",
      "batch_loss: 1.64 \n",
      "value: [0.8532753126692192, 0.4133337652696719, 1.2269423963868582, 0.20620714346329896, 2.5053587020886305, 0.18593880390189568, 0.4356071088181588]\n",
      "deadline: [0.99999213 0.598731   0.7032946  0.88567007 0.01209793 0.5193209\n",
      " 0.99969065]\n",
      "\n",
      "i 900\n",
      "batch_loss: 2.69 \n",
      "value: [1.0971147642938228, 0.9576246066160851, 1.8820009596100933, 1.8967385887158588, -0.21299777925297309, 0.638490401650273, 0.8886585242328698]\n",
      "deadline: [9.9999440e-01 4.2941727e-02 7.6073565e-02 1.8753825e-01 5.7171338e-04\n",
      " 3.2860506e-02 9.9961710e-01]\n",
      "\n",
      "i 1000\n",
      "batch_loss: 2.27 \n",
      "value: [1.9427899689227994, 1.5910454895052735, 2.0194017606090013, 1.6458384171144693, 0.6192126248422739, 0.14637073839259168, -0.47192111945619536]\n",
      "deadline: [9.9999571e-01 1.3359572e-02 1.9905997e-02 2.6755618e-02 1.5064250e-04\n",
      " 8.4623266e-03 9.9971753e-01]\n",
      "\n",
      "i 1100\n",
      "batch_loss: 2.74 \n",
      "value: [1.8429741267652608, 1.9249922300108404, 1.636390776944104, 2.3698268735979564, 0.7838695384316595, 0.12909350666232378, 0.06907203879479863]\n",
      "deadline: [9.9999642e-01 7.7151270e-03 1.0923785e-02 1.2344202e-02 8.6831962e-05\n",
      " 4.7291927e-03 9.9978584e-01]\n",
      "\n",
      "i 1200\n",
      "batch_loss: 1.64 \n",
      "value: [1.9829343507972783, 2.474510594001362, 2.2365927323195445, -0.8070888910340648, -0.9000991288178797, 1.7309627543978825, 2.0657111754515745]\n",
      "deadline: [9.9999690e-01 5.2981037e-03 7.3112757e-03 7.5741974e-03 6.0673032e-05\n",
      " 3.2120186e-03 9.9983251e-01]\n",
      "\n",
      "i 1300\n",
      "batch_loss: 2.75 \n",
      "value: [-0.3522435563665939, -1.5722653160366273, 1.0675146109339084, 1.5993824735161908, -0.3460308627079478, -0.3958310855663672, 0.08024972104841185]\n",
      "deadline: [9.9999726e-01 3.9583524e-03 5.3764656e-03 5.2692085e-03 4.6282006e-05\n",
      " 2.3891190e-03 9.9986541e-01]\n",
      "\n",
      "i 1400\n",
      "batch_loss: 2.24 \n",
      "value: [1.5059328216542482, 0.19167182554207296, 1.7434229736744093, 0.2873778501068502, 0.3650805732816613, -0.2546443336584918, 0.020743894264157736]\n",
      "deadline: [9.9999762e-01 3.1011044e-03 4.1660666e-03 3.9218511e-03 3.7037920e-05\n",
      " 1.8684674e-03 9.9989033e-01]\n",
      "\n",
      "i 1500\n",
      "batch_loss: 2.70 \n",
      "value: [0.6878671621249738, 2.292614340067706, 0.7103044562412606, -0.0971491422657468, 1.285666579868099, 0.9387548316669224, 1.682363073797817]\n",
      "deadline: [9.9999785e-01 2.5181726e-03 3.3561860e-03 3.0639907e-03 3.0695930e-05\n",
      " 1.5166714e-03 9.9990714e-01]\n",
      "\n",
      "i 1600\n",
      "batch_loss: 2.05 \n",
      "value: [1.7340401808764903, 1.359848427653795, 0.582257776277406, -0.08452102899485936, 1.595236404311302, -0.1002616195980224, 0.9379395251984268]\n",
      "deadline: [9.9999797e-01 2.0863416e-03 2.7635533e-03 2.4601405e-03 2.5946341e-05\n",
      " 1.2570178e-03 9.9992228e-01]\n",
      "\n",
      "i 1700\n",
      "batch_loss: 3.31 \n",
      "value: [-0.3272849589044306, -0.7039795565400103, -0.5734264505538404, 0.7933119079127383, 1.4952480234362793, 0.611036617727905, -0.295674730041466]\n",
      "deadline: [9.9999821e-01 1.7661511e-03 2.3283616e-03 2.0304711e-03 2.2381093e-05\n",
      " 1.0648998e-03 9.9993360e-01]\n",
      "\n",
      "i 1800\n",
      "batch_loss: 2.43 \n",
      "value: [1.2822114965686662, 0.5536412121628226, 0.01469079253600427, 1.2095779737625911, 0.3770912336785991, 0.2039473088919841, 1.8980750845988197]\n",
      "deadline: [9.9999833e-01 1.5109170e-03 1.9841469e-03 1.6994615e-03 1.9502178e-05\n",
      " 9.1192580e-04 9.9994254e-01]\n",
      "\n",
      "i 1900\n",
      "batch_loss: 1.77 \n",
      "value: [1.47460218034388, 1.4122789422185318, 0.5615802647486973, -0.07238937914969357, -0.2144588246516306, 2.361153184722794, -0.25916624028564]\n",
      "deadline: [9.9999845e-01 1.3098258e-03 1.7146954e-03 1.4461763e-03 1.7203382e-05\n",
      " 7.9145085e-04 9.9994957e-01]\n",
      "\n",
      "i 2000\n",
      "batch_loss: 3.08 \n",
      "value: [0.5384410121088677, 0.1360060981266319, -0.2681663766320755, 0.6435501024338843, 0.39770952866955944, 0.2586249486134602, 0.37508429974559043]\n",
      "deadline: [9.9999869e-01 1.1449205e-03 1.4949185e-03 1.2436280e-03 1.5292791e-05\n",
      " 6.9265097e-04 9.9995553e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        X_train_list.append(\n",
    "            torch.from_numpy(np.array(X_train[index_random])).cuda().type(torch.float32))\n",
    "        denominator += 1\n",
    "\n",
    "    h_delay_max, h_delay_sum, deadline_R, delay_R = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"i\", i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum / denominator))\n",
    "        print(\"value:\", X_train[index_random])\n",
    "        print(\"deadline:\", deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:04.227102Z",
     "start_time": "2021-03-08T07:19:04.220092Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 3.08 \n",
      "value: [0.5384410121088677, 0.1360060981266319, -0.2681663766320755, 0.6435501024338843, 0.39770952866955944, 0.2586249486134602, 0.37508429974559043]\n",
      "deadline: [9.9999869e-01 1.1449205e-03 1.4949185e-03 1.2436280e-03 1.5292791e-05\n",
      " 6.9265097e-04 9.9995553e-01]\n",
      "delay: 3.8099732398986816\n"
     ]
    }
   ],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum / denominator))\n",
    "print(\"value:\", X_train[index_random])\n",
    "print(\"deadline:\", deadline_R)\n",
    "print(\"delay:\", delay_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:07.373761Z",
     "start_time": "2021-03-08T07:19:04.228099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.6828660708386451, 2.5371777033894225)\n"
     ]
    }
   ],
   "source": [
    "def cost_sharing_with_deadline_old(test, t_c, target):\n",
    "    temp_max_delay_list = [0 for i in range(len(test))]\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if (item + 1e-4 >= target / k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if (count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True\n",
    "            break\n",
    "        if (k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = sum(t_c)\n",
    "            result = False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result\n",
    "\n",
    "\n",
    "# Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay = 0\n",
    "    max_delay = 0\n",
    "    test_number = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number += 1\n",
    "        temp_max_delay = 0\n",
    "        temp_delay = 0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "\n",
    "        temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline_old(\n",
    "            test_change, copy.deepcopy(deadline_list), 1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change)\n",
    "            test_i = np.delete(test_i, j)\n",
    "\n",
    "            deadline_i = copy.deepcopy(deadline_list)\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "\n",
    "            temp_max_delay_i_list, temp_sum_delay_i, judge_i = cost_sharing_with_deadline_old(\n",
    "                test_i, deadline_i, 1.0)\n",
    "\n",
    "            if (judge_i == False):\n",
    "                temp_sum_delay += (1.0 - deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0 - deadline_list[j])\n",
    "\n",
    "        max_delay += max(temp_max_delay_list)\n",
    "\n",
    "        sum_delay += temp_sum_delay\n",
    "\n",
    "#     print(\"deadline: \", deadline_list)\n",
    "#     print(\"sum_delay: \", sum_delay / test_number)\n",
    "#     print(\"max_delay: \", max_delay / test_number)\n",
    "#     print()\n",
    "    return max_delay / test_number, sum_delay / test_number\n",
    "\n",
    "\n",
    "print(run_cs_old(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:07.382282Z",
     "start_time": "2021-03-08T07:19:07.374692Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_with_deadline_7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:08.007336Z",
     "start_time": "2021-03-08T07:19:07.382973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (0.6868602300196887, 2.529187353821177)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Foo(object):\n",
    "\n",
    "    def __init__(self, test_item, test_change_item, deadline):\n",
    "        self.test_item = test_item\n",
    "        self.test_change_item = test_change_item\n",
    "        self.deadline = deadline\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.test_change_item < other.test_change_item\n",
    "def cost_sharing_with_deadline_free(n,_i,numbers_of_people_will_pay,started_k):\n",
    "    \n",
    "    for k in range(started_k,0,-1):\n",
    "        if(n-_i<=k):\n",
    "            x=k-1\n",
    "        else:\n",
    "            x=k\n",
    "        #print(n,_i,x,numbers_of_people_will_pay[x],k)\n",
    "        if(numbers_of_people_will_pay[x]>=k):\n",
    "            return True,k\n",
    "    return False,0\n",
    "#Cost Sharing\n",
    "def run_cs_test(deadline_list):\n",
    "    sum_delay=0\n",
    "    max_delay=0\n",
    "    test_number=0\n",
    "    seconds_start=time.time()\n",
    "    for i in range(len(X_test)):\n",
    "#        if(i%1000==0):\n",
    "#            seconds=time.time()\n",
    "#            print(\"times: \",seconds-seconds_start)\n",
    "        test_number+=1\n",
    "        temp_max_delay=0\n",
    "        temp_delay=0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change_temp = []\n",
    "        Foo_list = []\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        \n",
    "        for j in range(len(test)):\n",
    "            test_change_temp.append(test[j] * deadline_list[j])\n",
    "            Foo_list.append(Foo(test[j],test_change_temp[j],deadline_list[j]))\n",
    "            \n",
    "        Foo_list.sort(reverse=False)\n",
    "        \n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test[j]=Foo_list[j].test_item\n",
    "            test_change_temp[j]=Foo_list[j].test_change_item\n",
    "            deadline_list[j]=Foo_list[j].deadline\n",
    "\n",
    "        test_change = copy.deepcopy(test_change_temp);\n",
    "        \n",
    "        numbers_of_people_will_pay = [-10 for ii in range(len(test_change)+2)]#pay 1/k\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        k = 1\n",
    "        started=len(test_change)-1\n",
    "        end_k=-10\n",
    "        for j in range(len(test_change)):\n",
    "            if(k<=len(test_change)):\n",
    "                for people_id in range(started,-1,-1):\n",
    "                    if(test_change[people_id]+1e-9>=1.0/k):\n",
    "                        started=people_id\n",
    "                        numbers_of_people_will_pay[k]=len(test_change)-people_id\n",
    "                        end_k=len(test_change)-people_id\n",
    "                    else:\n",
    "                        k+=1\n",
    "                        break;\n",
    "                    \n",
    "        for j in range(k,len(test_change)+1):\n",
    "            numbers_of_people_will_pay[j]=end_k\n",
    "            \n",
    "        deadlist_new=copy.deepcopy(deadline_list)\n",
    "        \n",
    "        temp_max_delay_list,temp_sum_delay,judge_i =  cost_sharing_with_deadline(test_change,\n",
    "                        deadlist_new,1.0)\n",
    "        \n",
    "        judge_i= True\n",
    "        started_k = len(test)\n",
    "        for _i in range(len(test_change)):\n",
    "            if judge_i:\n",
    "                judge_i,started_k =  cost_sharing_with_deadline_free(len(test_change),\n",
    "                    _i,numbers_of_people_will_pay,started_k)\n",
    "                \n",
    "                \n",
    "            started_k+=1\n",
    "            if(judge_i==False):\n",
    "                temp_sum_delay += (1.0-deadline_list[_i])\n",
    "                temp_max_delay_list[_i] += (1.0-deadline_list[_i])\n",
    "        \n",
    "        max_delay+=max(temp_max_delay_list)\n",
    "        \n",
    "        sum_delay+=temp_sum_delay\n",
    "        \n",
    "                \n",
    "    #print(\"max_delay\",max_delay/test_number);\n",
    "                \n",
    "\n",
    "    return max_delay/test_number,sum_delay/test_number\n",
    "\n",
    "    \n",
    "print(\"test:\",run_cs_test(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:47.447662Z",
     "start_time": "2021-03-08T07:19:08.008332Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay: 0.5141159999999918 deadline: 0.47\n",
      "sum_dealy: 1.8999660000001117 deadline: 0.59\n"
     ]
    }
   ],
   "source": [
    "list_1=[]\n",
    "list_2=[]\n",
    "list_3=[]\n",
    "for i in range(1,101):\n",
    "    x=float(i)/100\n",
    "    xx=[x for i in range(Agent_number_n)]\n",
    "    #print(xx)\n",
    "    res1,res2=run_cs_test(xx)\n",
    "    list_1.append(res1)\n",
    "    list_2.append(res2)\n",
    "    list_3.append(x)\n",
    "print(\"max_delay:\",min(list_1),\"deadline:\",list_3[list_1.index(min(list_1))])\n",
    "print(\"sum_dealy:\",min(list_2),\"deadline:\",list_3[list_2.index(min(list_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:26:45.560501Z",
     "start_time": "2021-03-08T07:26:42.256976Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 1.8418 one_deadline: 1.8999660000001117\n",
      "NN: 1.833 one_deadline: 1.8999660000001117\n",
      "96.5280%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "\n",
    "xx = [0 for i in range(Agent_number_n)]\n",
    "for i in range(int ((Agent_number_n+1)/2)):\n",
    "    xx[i]=1\n",
    "print(\"NN:\",run_cs_old(xx)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"NN:\",run_cs_test(xx)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(xx)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:51.573854Z",
     "start_time": "2021-03-08T07:19:47.448626Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 2.553969112407448 one_deadline: 1.8999660000001117\n",
      "133.1806%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T07:19:55.568033Z",
     "start_time": "2021-03-08T07:19:51.574817Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay\n",
      "NN: 0.6888570440357551 one_deadline: 0.5141159999999918\n",
      "133.6002%\n"
     ]
    }
   ],
   "source": [
    "print(\"max_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[0],\"one_deadline:\",min(list_1))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[0]/min(list_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341.4px",
    "left": "535px",
    "right": "20px",
    "top": "92px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
