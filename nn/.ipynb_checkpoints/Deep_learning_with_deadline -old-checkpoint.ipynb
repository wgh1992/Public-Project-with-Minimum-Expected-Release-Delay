{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T08:15:37.030433Z",
     "start_time": "2021-03-03T08:15:36.066693Z"
    }
   },
   "outputs": [],
   "source": [
    "! jt -t gruvboxd -T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-03T07:51:38.375Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext pycodestyle_magic\n",
    "!echo \"111\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:30:43.007941Z",
     "start_time": "2021-03-03T07:30:42.986834Z"
    },
    "code_folding": [],
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "a = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:51.772780Z",
     "start_time": "2021-03-03T07:47:51.769159Z"
    }
   },
   "outputs": [],
   "source": [
    "%%pycodestyle\n",
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:54.274272Z",
     "start_time": "2021-03-03T07:47:54.242988Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 3\n",
    "\n",
    "number_of_groups = 2\n",
    "\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0.15\n",
    "Normal_loc2 = 0.85\n",
    "Normal_scale1 = 0.1\n",
    "Normal_scale2 = 0.1\n",
    "Distribution_number = 10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:57.748319Z",
     "start_time": "2021-03-03T07:47:57.737324Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:58.207833Z",
     "start_time": "2021-03-03T07:47:58.184381Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7:48: W291 trailing whitespace\n",
      "15:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "%%pycodestyle\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../distribution/twopeak.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train,  X_test = train_test_split(value_list, \n",
    "                                    test_size=0.5, random_state=seed)\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(X_train[:100])\n",
    "print(len(X_test))\n",
    "# run_cs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:48:01.066250Z",
     "start_time": "2021-03-03T07:48:01.032327Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7:18: E703 statement ends with a semicolon\n",
      "8:18: E703 statement ends with a semicolon\n",
      "12:27: E703 statement ends with a semicolon\n",
      "14:33: E703 statement ends with a semicolon\n",
      "15:40: E225 missing whitespace around operator\n",
      "17:17: E225 missing whitespace around operator\n",
      "18:27: E225 missing whitespace around operator\n",
      "18:34: E703 statement ends with a semicolon\n",
      "19:19: E225 missing whitespace around operator\n",
      "19:24: E261 at least two spaces before inline comment\n",
      "19:24: E262 inline comment should start with '# '\n",
      "20:18: E703 statement ends with a semicolon\n",
      "21:13: E225 missing whitespace around operator\n",
      "22:13: E265 block comment should start with '# '\n",
      "23:32: E225 missing whitespace around operator\n",
      "24:27: E225 missing whitespace around operator\n",
      "24:42: E703 statement ends with a semicolon\n",
      "25:19: E225 missing whitespace around operator\n",
      "25:25: E261 at least two spaces before inline comment\n",
      "25:25: E262 inline comment should start with '# '\n",
      "27:31: E231 missing whitespace after ','\n",
      "27:46: E231 missing whitespace after ','\n",
      "29:1: W391 blank line at end of file\n"
     ]
    }
   ],
   "source": [
    "% % pycodestyle\n",
    "\n",
    "\n",
    "def cost_sharing_with_deadline(test, t_c, target):\n",
    "    temp_max_delay_list = torch.zeros(len(test)).cuda()\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if(item + 1e-4 >= target/k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if(count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True  # 1.0#True\n",
    "            break\n",
    "        if(k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = torch.sum(t_c)\n",
    "            result = False  # 0.0#False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.690726Z",
     "start_time": "2021-03-03T07:47:34.414Z"
    }
   },
   "outputs": [],
   "source": [
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 50\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(\n",
    "            Agent_number_n, requires_grad=True), requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, value_list):  # type_offender val_offender   ;  type_defender val_defender\n",
    "\n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        # 把鸡蛋放到篮子里, requires_grad是参不参与误差反向传播, 要不要计算梯度\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        #h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)       # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        deadline = torch.sigmoid((h4+1)*10)\n",
    "        #deadline = torch.sigmoid(self.deadline)\n",
    "        # print(deadline)\n",
    "        # return\n",
    "\n",
    "        deadline_i_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "            deadline_i = []\n",
    "            for j in range(Agent_number_n):\n",
    "                if(i != j):\n",
    "                    deadline_i.append(float(deadline[j]))\n",
    "            deadline_i_list.append(deadline_i)\n",
    "        deadline_i_list = torch.Tensor(deadline_i_list)\n",
    "\n",
    "        lack_matrix = [[] for k in range(Agent_number_n)]  # k means lack of k\n",
    "        for k in range(len(value_list)):\n",
    "            test = value_list[k]\n",
    "            for i in range(Agent_number_n):\n",
    "                test_i = []\n",
    "                for j in range(Agent_number_n):\n",
    "                    if(i != j):\n",
    "                        test_i.append(float(test[j] * deadline[j]))\n",
    "                lack_matrix[i].append(test_i)\n",
    "\n",
    "        temp_sum_delay_total = torch.zeros(1).cuda()\n",
    "        temp_max_delay_total = torch.zeros(1).cuda()\n",
    "\n",
    "#         print(deadline)\n",
    "#         for i in range(Agent_number_n):\n",
    "#              print(deadline[i].requires_grad)\n",
    "#         return\n",
    "\n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "\n",
    "            # print(value_tensor.cpu())\n",
    "\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            #test_change = copy.deepcopy(X_test[i]);\n",
    "            test_change = []\n",
    "\n",
    "            for i in range(len(test)):\n",
    "                test_change.append(test[i] * deadline[i])\n",
    "\n",
    "            temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline(test_change,\n",
    "                                                                                     deadline, 1.0)\n",
    "            temp_max_delay_list = temp_max_delay_list.cuda()\n",
    "\n",
    "            temp_max_delay_list_copy = torch.zeros(\n",
    "                Agent_number_n, requires_grad=True)\n",
    "            for i in range(Agent_number_n):\n",
    "                temp_max_delay_list_copy[i] = temp_max_delay_list_copy[i] + \\\n",
    "                    temp_max_delay_list[i]\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                Possible = 0\n",
    "                deadline_i = deadline_i_list[i]\n",
    "                for j in range(len(lack_matrix[i])):\n",
    "                    test_i = lack_matrix[i][j]\n",
    "                    temp_max_delay_i, temp_sum_delay_i, judge_i = cost_sharing_with_deadline(test_i,\n",
    "                                                                                             deadline_i, 1.0)\n",
    "                    if(judge_i == False):\n",
    "                        Possible = Possible + 1.0\n",
    "                temp = (1.0-deadline[i].clone()) * \\\n",
    "                    torch.tensor(Possible/len(lack_matrix[i])).cuda()\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "#                 print(k,i)\n",
    "#                 print(deadline[i],deadline[i].requires_grad)\n",
    "#                 print(deadline[i].clone(),deadline[i].clone().requires_grad)\n",
    "#                 print(temp_max_delay_list[i],temp_max_delay_list[i].requires_grad)\n",
    "#                 print(temp,temp.requires_grad)\n",
    "#                 print()\n",
    "                temp_max_delay_list_copy[i] = temp_max_delay_list_copy[i] + temp\n",
    "\n",
    "            temp_sum_delay_total = temp_sum_delay_total + temp_sum_delay\n",
    "            temp_max_delay_total = temp_max_delay_total + \\\n",
    "                torch.max(temp_max_delay_list)\n",
    "#         for i in range(Agent_number_n):\n",
    "#             print(temp_max_delay_list[i].requires_grad)\n",
    "\n",
    "#         return\n",
    "\n",
    "        return temp_max_delay_total, temp_sum_delay_total, deadline.cpu().data.numpy(), float(temp_sum_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.691723Z",
     "start_time": "2021-03-03T07:47:34.415Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.692720Z",
     "start_time": "2021-03-03T07:47:34.416Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.693718Z",
     "start_time": "2021-03-03T07:47:34.417Z"
    }
   },
   "outputs": [],
   "source": [
    "#net = torch.load(\"Deep_learning_with_deadline_5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.694715Z",
     "start_time": "2021-03-03T07:47:34.418Z"
    }
   },
   "outputs": [],
   "source": [
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.695712Z",
     "start_time": "2021-03-03T07:47:34.420Z"
    }
   },
   "outputs": [],
   "source": [
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00005)\n",
    "\n",
    "batch_size = 32\n",
    "echo = 501"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.696710Z",
     "start_time": "2021-03-03T07:47:34.421Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list=[]\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0,len(X_train)-1)\n",
    "        X_train_list.append(torch.from_numpy(X_train[index_random]).cuda().type(torch.float32))\n",
    "        denominator+=1\n",
    "        \n",
    "    h_delay_max,h_delay_sum,deadline_R,delay_R   = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "        \n",
    "        \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"i\",i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum/denominator))\n",
    "        print(\"value:\" , X_train[index_random])\n",
    "        print(\"deadline:\" , deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.696710Z",
     "start_time": "2021-03-03T07:47:34.422Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum/denominator))\n",
    "print(\"value:\" , X_train[index_random])\n",
    "print(\"deadline:\" , deadline_R)\n",
    "print(\"delay:\" , delay_R)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T02:57:33.387390Z",
     "start_time": "2021-01-28T02:52:12.117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.697707Z",
     "start_time": "2021-03-03T07:47:34.426Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(net, \"Deep_learning_with_deadline_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.698705Z",
     "start_time": "2021-03-03T07:47:34.428Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline_old(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-4>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result\n",
    "\n",
    "\n",
    "\n",
    "#Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay=0\n",
    "    max_delay=0\n",
    "    test_number=0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number+=1\n",
    "        temp_max_delay=0\n",
    "        temp_delay=0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "            \n",
    "        \n",
    "        temp_max_delay_list,temp_sum_delay,judge1 = cost_sharing_with_deadline_old(test_change,\n",
    "                        copy.deepcopy(deadline_list),1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change);\n",
    "            test_i = np.delete(test_i, j)\n",
    "            \n",
    "            deadline_i = copy.deepcopy(deadline_list);\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "            \n",
    "            temp_max_delay_i_list,temp_sum_delay_i,judge_i = cost_sharing_with_deadline_old(test_i,\n",
    "                        deadline_i,1.0)\n",
    "            \n",
    "            if(judge_i==False):\n",
    "                temp_sum_delay += (1.0-deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0-deadline_list[j])\n",
    "                \n",
    "            \n",
    "        \n",
    "        max_delay+=max(temp_max_delay_list)\n",
    "        \n",
    "        sum_delay+=temp_sum_delay\n",
    "        \n",
    "    print(\"deadline: \",deadline_list)\n",
    "    print(\"sum_delay: \",sum_delay/test_number)\n",
    "    print(\"max_delay: \",max_delay/test_number)\n",
    "    print()\n",
    "    return max_delay/test_number,sum_delay/test_number\n",
    "    \n",
    "print(run_cs_old(deadline_R))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-03T07:47:34.699703Z",
     "start_time": "2021-03-03T07:47:34.430Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(net, \"Deep_learning_with_deadline_n=3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {
    "height": "205px",
    "width": "228px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "245.76px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
