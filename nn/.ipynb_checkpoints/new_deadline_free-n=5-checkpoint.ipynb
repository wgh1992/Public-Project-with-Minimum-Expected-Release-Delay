{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:41.037550Z",
     "start_time": "2021-03-06T13:25:39.890576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:41.047101Z",
     "start_time": "2021-03-06T13:25:41.039576Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 5\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = -0.1\n",
    "Normal_loc2 = 1.1\n",
    "Normal_scale1 = 0.2\n",
    "Normal_scale2 = 0.2\n",
    "Distribution_number = 10000\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "order = \"twopeaknormal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:42.221589Z",
     "start_time": "2021-03-06T13:25:41.049518Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[-0.31630055  0.09935802 -0.20920435  0.21354782  1.26616639]\n",
      " [ 1.01245883  1.23001997  1.22218262  1.21249072 -0.44937008]\n",
      " [-0.14304195  0.87363005  1.15361674 -0.27107025 -0.0145055 ]]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../distribution/twopeaknormalwithoutlimit.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "# for i in range(len(value_list)):\n",
    "#     for j in range(len(value_list[0])):\n",
    "#         if (value_list[i][j] <= 0):\n",
    "#             value_list[i][j] = 0\n",
    "#         if (value_list[i][j] >= 1):\n",
    "#             value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:42.239540Z",
     "start_time": "2021-03-06T13:25:42.223555Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:43.447087Z",
     "start_time": "2021-03-06T13:25:42.242504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9564)\n",
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:43.455575Z",
     "start_time": "2021-03-06T13:25:43.448084Z"
    }
   },
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return bits*0\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(Agent_number_n).cuda() - bits\n",
    "    paymentBits = negBits*1000\n",
    "\n",
    "    \n",
    "    cost_sharing_payment = 1.0/torch.sum(bits).item()\n",
    "\n",
    "    payments = bits * cost_sharing_payment\n",
    "    payments += paymentBits\n",
    "    \n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits):\n",
    "    payments = bitsToPayments(bits)\n",
    "    \n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    \n",
    "    if torch.sum(newBits).item() == 0:\n",
    "        return newBits\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "    \n",
    "def tpToTotalDelay(tp, deadline, _i):\n",
    "    ans = tpToBits(tp, torch.ones(Agent_number_n).type(torch.uint8).cuda())\n",
    "    if(torch.sum(ans).item()==0):\n",
    "        return torch.sum((1.0 - ans) * deadline), False\n",
    "    else:\n",
    "        return torch.sum((1.0 - ans) * deadline), True\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp,torch.ones(Agent_number_n).type(torch.uint8).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:43.470536Z",
     "start_time": "2021-03-06T13:25:43.457061Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-9>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:43.489522Z",
     "start_time": "2021-03-06T13:25:43.471534Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 50\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(Agent_number_n,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, value_list):\n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        # h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)  # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        deadline = torch.sigmoid((h4 + 1))\n",
    "        # deadline = torch.sigmoid(self.deadline)\n",
    "        # print(deadline)\n",
    "        # return\n",
    "\n",
    "        Possible_i_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "\n",
    "            Possible = 0\n",
    "            for k in range(len(value_list)):\n",
    "                value_tensor = value_list[k]\n",
    "                test = copy.deepcopy(value_tensor)\n",
    "                test_change = copy.deepcopy(test)\n",
    "                test_change = deadline * test_change\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "\n",
    "                judge_i = tpToTotalDelay(tp_0, deadline, i)[1]\n",
    "                \n",
    "#                 temp_max_delay_list,temp_sum_delay,judge_ii =  cost_sharing_with_deadline(tp_0,\n",
    "#                         deadline,1.0)\n",
    "#                 if (judge_i != judge_ii):\n",
    "#                     print(\"false\")\n",
    "#                     return\n",
    "                \n",
    "                \n",
    "                if (judge_i == True):\n",
    "                    Possible = Possible + 1.0/len(value_list)\n",
    "\n",
    "            Possible_i_list.append(Possible)\n",
    "\n",
    "        temp_sum_delay_total = torch.zeros(1).cuda()\n",
    "        temp_max_delay_total = torch.zeros(1).cuda()\n",
    "\n",
    "#         print(\"deadline:\",deadline)\n",
    "\n",
    "\n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            test_change = copy.deepcopy(test)\n",
    "            test_change = deadline * test_change\n",
    "\n",
    "            temp_sum_delay = 0\n",
    "            temp_max_delay = 0\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                tp_1 = test_change.clone()\n",
    "                tp_1[i] = 1\n",
    "                # tp_0 = copy.deepcopy(test_change_i)\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "                offer = tpToPayments(tp_1)[i]\n",
    "\n",
    "                Delay_1 = tpToTotalDelay(tp_1, deadline, i)[0]\n",
    "                Delay_2 = tpToTotalDelay(tp_0, deadline, i)[0]\n",
    "\n",
    "                temp = ((1.0 - cdf(offer/deadline[i], order)) * Delay_1 + cdf(\n",
    "                    offer/deadline[i], order) * Delay_2)/Agent_number_n\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "#                 print(\"test_change\",test_change)\n",
    "                \n",
    "#                 print(\"offer\",offer,cdf(offer/deadline[i], order))\n",
    "#                 print(\"temp\",temp)\n",
    "#                 print(\"Delay_1\", Delay_1)\n",
    "#                 print(\"Delay_2\", Delay_2)\n",
    "\n",
    "#                 print()\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "#             print(\"test_change\",test_change)\n",
    "#             print(\"deadline\",deadline)\n",
    "#             print(\"offer\",offer)\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "\n",
    "#             return\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                Possible = Possible_i_list[i]\n",
    "\n",
    "                temp = (1.0-deadline[i].clone()) * \\\n",
    "                    torch.tensor(1.0-Possible).cuda()\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "            temp_sum_delay_total = temp_sum_delay_total + temp_sum_delay\n",
    "\n",
    "        return temp_max_delay_total, temp_sum_delay_total, deadline.cpu(\n",
    "        ).data.numpy(), float(temp_sum_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:25:43.497497Z",
     "start_time": "2021-03-06T13:25:43.490482Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "#net = torch.load(\"Deep_learning_with_deadline_5\")\n",
    "\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00005)\n",
    "\n",
    "batch_size = 32\n",
    "echo = 2001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:19.555135Z",
     "start_time": "2021-03-06T13:25:43.498462Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch_loss: 2.41 \n",
      "value: [-0.09572344487416709, -0.302336727326396, 1.0587140091375684, 1.3219106579156554, 1.383915649204699]\n",
      "deadline: [0.7398518  0.7395586  0.71836317 0.67674243 0.703254  ]\n",
      "\n",
      "i 200\n",
      "batch_loss: 2.23 \n",
      "value: [-0.12882498207945756, -0.21876380377370216, 0.03718021702596469, 0.07180559275827006, -0.19866809254831005]\n",
      "deadline: [0.7141849  0.7127293  0.7096712  0.62502044 0.6593668 ]\n",
      "\n",
      "i 400\n",
      "batch_loss: 2.92 \n",
      "value: [1.1702102036033646, 1.1276388344622603, -0.057668736691906974, 1.263442170637798, 1.3489991946552908]\n",
      "deadline: [0.6512453 0.6343338 0.6947215 0.4940502 0.5554427]\n",
      "\n",
      "i 600\n",
      "batch_loss: 2.35 \n",
      "value: [1.3376500540720802, 1.1538441162342175, 0.9050061593370922, 0.1393254194571448, 0.018711501857352972]\n",
      "deadline: [0.60618216 0.5627776  0.6727527  0.36338916 0.46739557]\n",
      "\n",
      "i 800\n",
      "batch_loss: 2.89 \n",
      "value: [1.0722214506453618, -0.5474881069203098, -0.038202301218738445, -0.05977990734062175, 1.2817312305160018]\n",
      "deadline: [0.6264219  0.5679479  0.67739666 0.20007424 0.47718117]\n",
      "\n",
      "i 1000\n",
      "batch_loss: 2.91 \n",
      "value: [1.0918921047737833, 1.3411331498653913, 0.017314038238174123, 1.375676045877423, 0.09497518835398294]\n",
      "deadline: [0.6853418  0.5749145  0.70126224 0.03277621 0.49078408]\n",
      "\n",
      "i 1200\n",
      "batch_loss: 2.51 \n",
      "value: [1.1792570440460541, 0.9444585986498385, 1.239260760790711, 0.7051437182151716, -0.24793219540081804]\n",
      "deadline: [0.75789016 0.5390471  0.7561058  0.01129571 0.5128252 ]\n",
      "\n",
      "i 1400\n",
      "batch_loss: 2.77 \n",
      "value: [1.099455891689686, -0.19079099394662538, 1.3910884262696963, 1.3438722416011941, 0.952400930470904]\n",
      "deadline: [0.8422683  0.49514103 0.81513953 0.00500407 0.46762735]\n",
      "\n",
      "i 1600\n",
      "batch_loss: 2.44 \n",
      "value: [1.003907869074307, -0.2481873853507013, 1.57795766657185, -0.10196708152674418, 0.07277407741402975]\n",
      "deadline: [9.42281485e-01 1.92986757e-01 9.30536330e-01 5.85268252e-04\n",
      " 1.16506085e-01]\n",
      "\n",
      "i 1800\n",
      "batch_loss: 2.31 \n",
      "value: [-0.15639290289512814, 0.7645704745736966, 0.0426667545720498, -0.13149635582854236, 1.0360195632407063]\n",
      "deadline: [9.8115808e-01 1.4891281e-02 9.8402065e-01 2.8393466e-05 1.0514748e-02]\n",
      "\n",
      "i 2000\n",
      "batch_loss: 2.11 \n",
      "value: [1.103898417315603, -0.24458092347865765, -0.30036913971928253, 1.1170277370817279, -0.00885274809981626]\n",
      "deadline: [9.9062854e-01 5.6163096e-03 9.9199450e-01 9.2870550e-06 4.0987809e-03]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        X_train_list.append(\n",
    "            torch.from_numpy(np.array(X_train[index_random])).cuda().type(torch.float32))\n",
    "        denominator += 1\n",
    "\n",
    "    h_delay_max, h_delay_sum, deadline_R, delay_R = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        print(\"i\", i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum / denominator))\n",
    "        print(\"value:\", X_train[index_random])\n",
    "        print(\"deadline:\", deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:19.561694Z",
     "start_time": "2021-03-06T13:58:19.556681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 2.11 \n",
      "value: [1.103898417315603, -0.24458092347865765, -0.30036913971928253, 1.1170277370817279, -0.00885274809981626]\n",
      "deadline: [9.9062854e-01 5.6163096e-03 9.9199450e-01 9.2870550e-06 4.0987809e-03]\n",
      "delay: 2.071765184402466\n"
     ]
    }
   ],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum / denominator))\n",
    "print(\"value:\", X_train[index_random])\n",
    "print(\"deadline:\", deadline_R)\n",
    "print(\"delay:\", delay_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:21.300848Z",
     "start_time": "2021-03-06T13:58:19.562666Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.7367632626012899, 2.329955761755353)\n"
     ]
    }
   ],
   "source": [
    "def cost_sharing_with_deadline_old(test, t_c, target):\n",
    "    temp_max_delay_list = [0 for i in range(len(test))]\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if (item + 1e-4 >= target / k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if (count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True\n",
    "            break\n",
    "        if (k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = sum(t_c)\n",
    "            result = False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result\n",
    "\n",
    "\n",
    "# Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay = 0\n",
    "    max_delay = 0\n",
    "    test_number = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number += 1\n",
    "        temp_max_delay = 0\n",
    "        temp_delay = 0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "\n",
    "        temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline_old(\n",
    "            test_change, copy.deepcopy(deadline_list), 1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change)\n",
    "            test_i = np.delete(test_i, j)\n",
    "\n",
    "            deadline_i = copy.deepcopy(deadline_list)\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "\n",
    "            temp_max_delay_i_list, temp_sum_delay_i, judge_i = cost_sharing_with_deadline_old(\n",
    "                test_i, deadline_i, 1.0)\n",
    "\n",
    "            if (judge_i == False):\n",
    "                temp_sum_delay += (1.0 - deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0 - deadline_list[j])\n",
    "\n",
    "        max_delay += max(temp_max_delay_list)\n",
    "\n",
    "        sum_delay += temp_sum_delay\n",
    "\n",
    "#     print(\"deadline: \", deadline_list)\n",
    "#     print(\"sum_delay: \", sum_delay / test_number)\n",
    "#     print(\"max_delay: \", max_delay / test_number)\n",
    "#     print()\n",
    "    return max_delay / test_number, sum_delay / test_number\n",
    "\n",
    "\n",
    "print(run_cs_old(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:21.307814Z",
     "start_time": "2021-03-06T13:58:21.301820Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_with_deadline_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:21.782530Z",
     "start_time": "2021-03-06T13:58:21.308793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (0.7552379779344425, 2.4385577740551585)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Foo(object):\n",
    "\n",
    "    def __init__(self, test_item, test_change_item, deadline):\n",
    "        self.test_item = test_item\n",
    "        self.test_change_item = test_change_item\n",
    "        self.deadline = deadline\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.test_change_item < other.test_change_item\n",
    "def cost_sharing_with_deadline_free(n,_i,numbers_of_people_will_pay,started_k):\n",
    "    \n",
    "    for k in range(started_k,0,-1):\n",
    "        if(n-_i<=k):\n",
    "            x=k-1\n",
    "        else:\n",
    "            x=k\n",
    "        #print(n,_i,x,numbers_of_people_will_pay[x],k)\n",
    "        if(numbers_of_people_will_pay[x]>=k):\n",
    "            return True,k\n",
    "    return False,0\n",
    "#Cost Sharing\n",
    "def run_cs_test(deadline_list):\n",
    "    sum_delay=0\n",
    "    max_delay=0\n",
    "    test_number=0\n",
    "    seconds_start=time.time()\n",
    "    for i in range(len(X_test)):\n",
    "#        if(i%1000==0):\n",
    "#            seconds=time.time()\n",
    "#            print(\"times: \",seconds-seconds_start)\n",
    "        test_number+=1\n",
    "        temp_max_delay=0\n",
    "        temp_delay=0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change_temp = []\n",
    "        Foo_list = []\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        \n",
    "        for j in range(len(test)):\n",
    "            test_change_temp.append(test[j] * deadline_list[j])\n",
    "            Foo_list.append(Foo(test[j],test_change_temp[j],deadline_list[j]))\n",
    "            \n",
    "        Foo_list.sort(reverse=False)\n",
    "        \n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test[j]=Foo_list[j].test_item\n",
    "            test_change_temp[j]=Foo_list[j].test_change_item\n",
    "            deadline_list[j]=Foo_list[j].deadline\n",
    "\n",
    "        test_change = copy.deepcopy(test_change_temp);\n",
    "        \n",
    "        numbers_of_people_will_pay = [-10 for ii in range(len(test_change)+2)]#pay 1/k\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        k = 1\n",
    "        started=len(test_change)-1\n",
    "        end_k=-10\n",
    "        for j in range(len(test_change)):\n",
    "            if(k<=len(test_change)):\n",
    "                for people_id in range(started,-1,-1):\n",
    "                    if(test_change[people_id]+1e-9>=1.0/k):\n",
    "                        started=people_id\n",
    "                        numbers_of_people_will_pay[k]=len(test_change)-people_id\n",
    "                        end_k=len(test_change)-people_id\n",
    "                    else:\n",
    "                        k+=1\n",
    "                        break;\n",
    "                    \n",
    "        for j in range(k,len(test_change)+1):\n",
    "            numbers_of_people_will_pay[j]=end_k\n",
    "            \n",
    "        deadlist_new=copy.deepcopy(deadline_list)\n",
    "        \n",
    "        temp_max_delay_list,temp_sum_delay,judge_i =  cost_sharing_with_deadline(test_change,\n",
    "                        deadlist_new,1.0)\n",
    "        \n",
    "        judge_i= True\n",
    "        started_k = len(test)\n",
    "        for _i in range(len(test_change)):\n",
    "            if judge_i:\n",
    "                judge_i,started_k =  cost_sharing_with_deadline_free(len(test_change),\n",
    "                    _i,numbers_of_people_will_pay,started_k)\n",
    "                \n",
    "                \n",
    "            started_k+=1\n",
    "            if(judge_i==False):\n",
    "                temp_sum_delay += (1.0-deadline_list[_i])\n",
    "                temp_max_delay_list[_i] += (1.0-deadline_list[_i])\n",
    "        \n",
    "        max_delay+=max(temp_max_delay_list)\n",
    "        \n",
    "        sum_delay+=temp_sum_delay\n",
    "        \n",
    "                \n",
    "    #print(\"max_delay\",max_delay/test_number);\n",
    "                \n",
    "\n",
    "    return max_delay/test_number,sum_delay/test_number\n",
    "\n",
    "    \n",
    "print(\"test:\",run_cs_test(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:46.861218Z",
     "start_time": "2021-03-06T13:58:21.784608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay: 0.6513340000000387 deadline: 0.53\n",
      "sum_dealy: 2.3144120000000434 deadline: 0.78\n"
     ]
    }
   ],
   "source": [
    "list_1=[]\n",
    "list_2=[]\n",
    "list_3=[]\n",
    "for i in range(1,101):\n",
    "    x=float(i)/100\n",
    "    xx=[x for i in range(Agent_number_n)]\n",
    "    #print(xx)\n",
    "    res1,res2=run_cs_test(xx)\n",
    "    list_1.append(res1)\n",
    "    list_2.append(res2)\n",
    "    list_3.append(x)\n",
    "print(\"max_delay:\",min(list_1),\"deadline:\",list_3[list_1.index(min(list_1))])\n",
    "print(\"sum_dealy:\",min(list_2),\"deadline:\",list_3[list_2.index(min(list_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T14:07:24.113311Z",
     "start_time": "2021-03-06T14:07:24.108323Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9.9199450e-01 5.6163096e-03 4.0987809e-03 9.2870550e-06 9.9062854e-01]\n"
     ]
    }
   ],
   "source": [
    "print(deadline_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:49.073596Z",
     "start_time": "2021-03-06T13:58:46.865909Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 2.375341092023762 one_deadline: 2.3144120000000434\n",
      "105.3647%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-06T13:58:51.270541Z",
     "start_time": "2021-03-06T13:58:49.074548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay\n",
      "NN: 0.7486223886325024 one_deadline: 0.6513340000000387\n",
      "115.9539%\n"
     ]
    }
   ],
   "source": [
    "print(\"max_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[0],\"one_deadline:\",min(list_1))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[0]/min(list_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341.4px",
    "left": "535px",
    "right": "20px",
    "top": "92px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
