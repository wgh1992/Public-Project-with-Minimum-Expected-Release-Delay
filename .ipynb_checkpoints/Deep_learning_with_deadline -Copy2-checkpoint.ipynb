{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.169352Z",
     "start_time": "2021-02-26T07:38:24.980257Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm \n",
    "import matplotlib.cm as cm\n",
    "\n",
    "\n",
    "\n",
    "from scipy.interpolate import griddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.176243Z",
     "start_time": "2021-02-26T07:38:26.171346Z"
    }
   },
   "outputs": [],
   "source": [
    "#global veriable \n",
    "Uniform_low_bound=0\n",
    "Uniform_up_bound=1\n",
    "Agent_number_n=3\n",
    "\n",
    "number_of_groups=2\n",
    "\n",
    "Normal_loc=0.5\n",
    "Normal_scale=0.2\n",
    "Normal_loc1=0.15\n",
    "Normal_loc2=0.85\n",
    "Normal_scale1=0.1\n",
    "Normal_scale2=0.1\n",
    "Distribution_number=10000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.250510Z",
     "start_time": "2021-02-26T07:38:26.178328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():  \n",
    "    dev = \"cuda:0\" \n",
    "else:  \n",
    "    dev = \"cpu\"  \n",
    "\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.352666Z",
     "start_time": "2021-02-26T07:38:26.251506Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1]\n",
      "5000\n",
      "[array([0, 0, 1]), array([1, 1, 1]), array([1, 0, 1]), array([1, 0, 1]), array([0, 0, 0]), array([1, 1, 1]), array([0, 0, 1]), array([0, 1, 0]), array([1, 0, 0]), array([1, 1, 0]), array([0, 0, 0]), array([0, 1, 1]), array([1, 1, 1]), array([0, 0, 0]), array([0, 0, 1]), array([0, 0, 1]), array([1, 0, 0]), array([1, 0, 0]), array([1, 0, 1]), array([1, 1, 1]), array([1, 0, 1]), array([1, 0, 0]), array([1, 1, 0]), array([0, 1, 0]), array([0, 1, 0]), array([1, 0, 1]), array([1, 1, 0]), array([0, 1, 0]), array([0, 0, 1]), array([0, 0, 0]), array([1, 0, 1]), array([1, 0, 0]), array([0, 0, 0]), array([0, 1, 1]), array([0, 1, 1]), array([0, 0, 0]), array([1, 0, 1]), array([1, 1, 0]), array([0, 0, 1]), array([0, 1, 1]), array([0, 1, 0]), array([0, 0, 1]), array([1, 1, 1]), array([1, 1, 1]), array([0, 1, 1]), array([0, 0, 1]), array([0, 1, 1]), array([0, 0, 0]), array([1, 0, 0]), array([1, 1, 0]), array([1, 0, 0]), array([1, 1, 1]), array([0, 1, 0]), array([1, 1, 0]), array([1, 1, 1]), array([0, 1, 0]), array([0, 0, 1]), array([0, 1, 0]), array([1, 1, 0]), array([1, 0, 1]), array([1, 0, 1]), array([0, 0, 1]), array([1, 1, 1]), array([0, 1, 0]), array([0, 1, 1]), array([0, 1, 0]), array([0, 1, 0]), array([0, 0, 1]), array([0, 0, 0]), array([1, 0, 1]), array([1, 1, 1]), array([0, 1, 0]), array([1, 0, 0]), array([1, 1, 0]), array([0, 1, 1]), array([1, 1, 0]), array([0, 0, 1]), array([1, 1, 0]), array([0, 0, 1]), array([1, 1, 1]), array([0, 0, 1]), array([1, 0, 1]), array([0, 0, 1]), array([0, 0, 1]), array([0, 0, 0]), array([1, 0, 1]), array([1, 0, 0]), array([1, 1, 0]), array([0, 0, 1]), array([0, 1, 1]), array([1, 0, 1]), array([1, 1, 1]), array([1, 0, 1]), array([0, 0, 1]), array([1, 1, 0]), array([1, 1, 0]), array([1, 0, 1]), array([0, 0, 0]), array([0, 0, 1]), array([0, 0, 1])]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "#exec(open('distribution/twopeak.py').read())\n",
    "exec(open('distribution/twopeak.py').read())\n",
    "#exec(open('distribution/normal.py').read())\n",
    "X_train,  X_test = train_test_split(value_list, test_size=0.5, random_state=seed)\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(X_train[:100])\n",
    "print(len(X_test))\n",
    "#run_cs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.359544Z",
     "start_time": "2021-02-26T07:38:26.353664Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay=0\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-6>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "\n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            if(k!=len(test)):\n",
    "                temp_max_delay=0##############\n",
    "            result=True#1.0#True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay=1\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False#0.0#False\n",
    "\n",
    "    return temp_max_delay,temp_sum_delay,result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.381492Z",
     "start_time": "2021-02-26T07:38:26.361540Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 100\n",
    "        num_output = Agent_number_n\n",
    "        \n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output   = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(Agent_number_n, requires_grad=True), requires_grad=True).cuda() \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, value_list): # type_offender val_offender   ;  type_defender val_defender\n",
    "        \n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        # 把鸡蛋放到篮子里, requires_grad是参不参与误差反向传播, 要不要计算梯度\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        #h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = torch.relu_(self.hidden_3(h3))\n",
    "        h5 = self.output(h4)       # no relu!!!!\n",
    "        deadline = torch.sigmoid(h5+5)#torch.sigmoid(self.deadline)# need more layer\n",
    "        #deadline = torch.sigmoid(self.deadline)\n",
    "        #print(deadline)\n",
    "        #return \n",
    "        \n",
    "        lack_matrix=[[] for k in range(Agent_number_n)] #k means lack of k\n",
    "        \n",
    "        for k in range(len(value_list)):\n",
    "            test=value_list[k]\n",
    "            for i in range(Agent_number_n):\n",
    "                test_i = []\n",
    "                deadline_i = []\n",
    "                for j in range(Agent_number_n):\n",
    "                    if(i!=j):\n",
    "                        test_i.append(test[j] * deadline[j])\n",
    "                        deadline_i.append(deadline[j]);\n",
    "                        \n",
    "                lack_matrix[i].append(deadline_i)\n",
    "                        \n",
    "\n",
    "        temp_sum_delay_total = 0\n",
    "        temp_max_delay_total = 0\n",
    "        \n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "            \n",
    "            #print(value_tensor.cpu())\n",
    "\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            #test_change = copy.deepcopy(X_test[i]);\n",
    "            test_change = []\n",
    "\n",
    "            for i in range(len(test)):\n",
    "                test_change.append(test[i] * deadline[i])\n",
    "\n",
    "\n",
    "            temp_max_delay,temp_sum_delay,judge1 = cost_sharing_with_deadline(test_change,\n",
    "                            deadline,1.0)\n",
    "            \n",
    "            for i in range(Agent_number_n):\n",
    "                \n",
    "                Possible=0\n",
    "                for j in range(len(lack_matrix[i])):\n",
    "                    test_i =  lack_matrix[i][j]\n",
    "                    temp_max_delay_i,temp_sum_delay_i,judge_i = cost_sharing_with_deadline(test_i,\n",
    "                                deadline_i,1.0)\n",
    "\n",
    "                    if(judge_i==False):\n",
    "                        Possible+=1.0\n",
    "                \n",
    "                temp_sum_delay += (1.0-deadline[i])*Possible/len(lack_matrix[i])\n",
    "                        \n",
    "            temp_sum_delay_total += temp_sum_delay\n",
    "        return temp_max_delay_total,temp_sum_delay_total,deadline.cpu().data.numpy(),float(temp_sum_delay)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:26.388467Z",
     "start_time": "2021-02-26T07:38:26.383480Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight, gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:27.688318Z",
     "start_time": "2021-02-26T07:38:26.390462Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net  = Net()\n",
    "#net.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:27.692355Z",
     "start_time": "2021-02-26T07:38:27.689315Z"
    }
   },
   "outputs": [],
   "source": [
    "#net = torch.load(\"Deep_learning_with_deadline_5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:27.711765Z",
     "start_time": "2021-02-26T07:38:27.693305Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (hidden_0): Linear(in_features=3, out_features=100, bias=True)\n",
       "  (hidden_1): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (hidden_2): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (hidden_3): Linear(in_features=100, out_features=100, bias=True)\n",
       "  (output): Linear(in_features=100, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-26T07:38:27.717749Z",
     "start_time": "2021-02-26T07:38:27.712763Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.0001)\n",
    "\n",
    "batch_size = 32 \n",
    "echo = 10001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-26T07:38:24.993Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1.77 \n",
      "value: [1 0 1]\n",
      "deadline: [0.99345773 0.99367875 0.9932567 ]\n",
      "\n",
      "batch: 1.77 \n",
      "value: [0 1 1]\n",
      "deadline: [0.9923429  0.99300873 0.9925695 ]\n",
      "\n",
      "batch: 2.01 \n",
      "value: [1 1 0]\n",
      "deadline: [0.9876523  0.99016005 0.9906103 ]\n",
      "\n",
      "batch: 1.69 \n",
      "value: [0 1 1]\n",
      "deadline: [0.88490486 0.9477555  0.96777433]\n",
      "\n",
      "batch: 1.80 \n",
      "value: [1 0 0]\n",
      "deadline: [0.02780408 0.6139737  0.8374899 ]\n",
      "\n",
      "batch: 1.62 \n",
      "value: [0 0 1]\n",
      "deadline: [0.01786839 0.8892735  0.9404112 ]\n",
      "\n",
      "batch: 1.65 \n",
      "value: [1 1 0]\n",
      "deadline: [0.00785735 0.94152296 0.9625375 ]\n",
      "\n",
      "batch: 1.52 \n",
      "value: [1 1 0]\n",
      "deadline: [0.00404193 0.96524453 0.9751614 ]\n",
      "\n",
      "batch: 1.33 \n",
      "value: [0 0 1]\n",
      "deadline: [0.00242029 0.9776162  0.98303926]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list=[]\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0,len(X_train)-1)\n",
    "        X_train_list.append(torch.from_numpy(X_train[index_random]).cuda().type(torch.float32))\n",
    "        denominator+=1\n",
    "        \n",
    "    h_delay_max,h_delay_sum,deadline_R,delay_R   = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "        \n",
    "        \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if i % 50 == 0:\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum/denominator))\n",
    "        print(\"value:\" , X_train[index_random])\n",
    "        print(\"deadline:\" , deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-26T07:38:24.995Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum/denominator),'，sum_average: %.2f' % float(loss_average))\n",
    "print(\"value:\" , X_train[index_random])\n",
    "print(\"deadline:\" , deadline_R)\n",
    "print(\"delay:\" , delay_R)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-28T02:57:33.387390Z",
     "start_time": "2021-01-28T02:52:12.117Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-02-26T07:38:24.997Z"
    }
   },
   "outputs": [],
   "source": [
    "#torch.save(net, \"Deep_learning_with_deadline_5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
