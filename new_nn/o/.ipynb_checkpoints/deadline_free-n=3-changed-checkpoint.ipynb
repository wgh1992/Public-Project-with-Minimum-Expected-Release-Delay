{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:10.775648Z",
     "start_time": "2021-03-22T06:33:09.026286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:10.790878Z",
     "start_time": "2021-03-22T06:33:10.776428Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 3\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0\n",
    "Normal_loc2 = 1.5\n",
    "Normal_scale1 = 0.2\n",
    "Normal_scale2 = 0.2\n",
    "Distribution_number = 5000\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "target = \"min_sum\" \n",
    "#target = \"min_max\"\n",
    "order = \"twopeaknormal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:11.151893Z",
     "start_time": "2021-03-22T06:33:10.792852Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500\n",
      "[[0.53629287 0.75777657 0.54006023]\n",
      " [0.33936184 0.49853522 0.99969725]\n",
      " [0.4513505  0.44359308 0.5307268 ]]\n",
      "2500\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../../distribution/normal.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "# for i in range(len(value_list)):\n",
    "#     for j in range(len(value_list[0])):\n",
    "#         if (value_list[i][j] <= 0):\n",
    "#             value_list[i][j] = 0\n",
    "#         if (value_list[i][j] >= 1):\n",
    "#             value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:11.168332Z",
     "start_time": "2021-03-22T06:33:11.152890Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:12.908761Z",
     "start_time": "2021-03-22T06:33:11.172356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6303)\n",
      "tensor(0.4969)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:12.940247Z",
     "start_time": "2021-03-22T06:33:12.909738Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 20\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_payment = torch.nn.Linear(num_hidden, num_output)\n",
    "\n",
    "        self.hidden_2_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_allocation = torch.nn.Linear(num_hidden, num_output)\n",
    "\n",
    "        self.hidden_2_3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_3_3 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output_o = torch.nn.Linear(num_hidden, 1)\n",
    "\n",
    "    def calculate(self, value_list):\n",
    "        h0 = torch.relu_(self.hidden_0(value_list))\n",
    "        h1 = torch.relu_(self.hidden_1(h0))\n",
    "        h2_1 = torch.relu_(self.hidden_2_1(h1))\n",
    "        h2_2 = torch.relu_(self.hidden_2_2(h1))\n",
    "        h2_3 = torch.relu_(self.hidden_2_3(h1))\n",
    "\n",
    "        h3_1 = torch.relu_(self.hidden_3_1(h2_1))\n",
    "        h3_2 = torch.relu_(self.hidden_3_2(h2_2))\n",
    "        h3_3 = torch.relu_(self.hidden_3_3(h2_3))\n",
    "        softmax = torch.nn.Softmax(dim=0)\n",
    "        payment = softmax(self.output_payment(h3_1))\n",
    "        allocation = torch.sigmoid(self.output_allocation(h3_2))\n",
    "        if_o = torch.sigmoid(self.output_o(h3_3))[0]\n",
    "\n",
    "        return payment, allocation, if_o\n",
    "\n",
    "    def forward(self, value_list):\n",
    "        value_list = torch.from_numpy(np.array(value_list)).cuda().type(\n",
    "            torch.float32)\n",
    "\n",
    "        payment = torch.zeros(Agent_number_n).cuda()\n",
    "\n",
    "        payment_temp, allocation, if_o = self.calculate(value_list)\n",
    "\n",
    "        loss_condition = 0\n",
    "        loss_sum_delay = 0\n",
    "        loss_max_delay = 0\n",
    "\n",
    "        for i in range(Agent_number_n):\n",
    "            devide = 10\n",
    "\n",
    "            loss_constant = 0\n",
    "\n",
    "            payment[i] = allocation[i] * value_list[i]\n",
    "            integral = 0\n",
    "\n",
    "            for c in range(devide + 1):\n",
    "                payment_change_1 = (torch.tensor(float(c) / devide)).cuda()\n",
    "                value_list_temp_1 = value_list.clone()\n",
    "                value_list_temp_1[i] = payment_change_1\n",
    "\n",
    "                payment_temp_1, allocation_temp_1, if_o_1 = self.calculate(\n",
    "                    value_list_temp_1)\n",
    "\n",
    "                payment_change_2 = (torch.tensor(float(c + 1) / devide)).cuda()\n",
    "                value_list_temp_2 = value_list.clone()\n",
    "                value_list_temp_2[i] = payment_change_2\n",
    "\n",
    "                payment_temp_2, allocation_temp_2, if_o_2 = self.calculate(\n",
    "                    value_list_temp_2)\n",
    "\n",
    "                loss_constant += torch.relu(allocation_temp_1[i] -\n",
    "                                            allocation_temp_2[i])\n",
    "\n",
    "                if ((torch.tensor(float(c) / devide)).cuda() < value_list[i]):\n",
    "                    integral += (torch.tensor(\n",
    "                        float(1) / devide)).cuda() * allocation_temp_1[i]\n",
    "                    loss_constant += torch.relu(allocation_temp_1[i] -\n",
    "                                                allocation[i])\n",
    "\n",
    "                elif ((torch.tensor(float(c + 1) / devide)).cuda() <\n",
    "                      value_list[i]):\n",
    "                    integral += (value_list[i] - (torch.tensor(\n",
    "                        float(1) / devide)).cuda()) * allocation_temp_1[i]\n",
    "                    loss_constant += torch.relu(allocation_temp_1[i] -\n",
    "                                                allocation[i])\n",
    "\n",
    "            loss_condition += loss_constant\n",
    "\n",
    "            loss_sub2 = value_list[i] * allocation[i] - payment[i]\n",
    "\n",
    "            loss_condition += torch.where(loss_sub2 < 0,\n",
    "                                          torch.square(loss_sub2) * 100,\n",
    "                                          torch.tensor(0.).cuda())\n",
    "\n",
    "            payment[i] -= integral\n",
    "\n",
    "            loss_condition += torch.square(payment[i] - payment_temp[i] * if_o) * 100\n",
    "            loss_condition += torch.relu(payment_temp[i] - value_list[i]) * if_o\n",
    "\n",
    "        loss_max_delay += torch.max(1.0 - allocation) * if_o + (1.0 - if_o)\n",
    "\n",
    "        loss_sum_delay += torch.sum(\n",
    "            1.0 - allocation) * if_o + Agent_number_n * (1.0 - if_o)\n",
    "\n",
    "        loss_condition = loss_condition * if_o * 100 + torch.relu(\n",
    "            torch.sigmoid(torch.sum(allocation) * 1000 - 10) -\n",
    "            torch.sum(payment) * if_o) * 100\n",
    "\n",
    "        if (target == \"min_sum\"):\n",
    "            loss = loss_sum_delay + loss_condition\n",
    "        if (target == \"min_max\"):\n",
    "            loss = loss_max_delay + loss_condition\n",
    "\n",
    "        return loss, loss_sum_delay, loss_max_delay, float(\n",
    "            loss_condition), [payment.cpu().data.numpy(),payment_temp.cpu().data.numpy()], allocation.cpu(\n",
    "            ).data.numpy(), if_o.cpu().data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-22T06:33:12.956204Z",
     "start_time": "2021-03-22T06:33:12.941217Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "net = torch.load(\"Deep_learning_3_2\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00005)\n",
    "\n",
    "batch_size = 8\n",
    "echo = 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-22T06:33:08.995Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch_loss: 103.49 \n",
      "\n",
      "sum:  2.94   max:  0.99\n",
      "condition:  99.96   total_loss:  102.90\n",
      "value:  [0.72052309 0.81988152 0.54242425]\n",
      "payment:  [array([0.03185874, 0.04005936, 0.02591161], dtype=float32), array([0.32121783, 0.29392022, 0.38486198], dtype=float32)]\n",
      "allocation:  [0.47117078 0.4151147  0.24824302]\n",
      "if_o: 0.051094413\n",
      "\n",
      "i 100\n",
      "batch_loss: 103.65 \n",
      "\n",
      "sum:  2.96   max:  0.99\n",
      "condition:  101.12   total_loss:  104.08\n",
      "value:  [0.57401542 0.4707266  0.8370671 ]\n",
      "payment:  [array([0.0267662 , 0.01845204, 0.08188596], dtype=float32), array([0.26282874, 0.23309027, 0.504081  ], dtype=float32)]\n",
      "allocation:  [0.25654536 0.23620218 0.42600182]\n",
      "if_o: 0.046452645\n",
      "\n",
      "i 200\n",
      "batch_loss: 103.51 \n",
      "\n",
      "sum:  2.95   max:  0.99\n",
      "condition:  100.42   total_loss:  103.37\n",
      "value:  [0.2697164  0.30886278 0.75591968]\n",
      "payment:  [array([ 0.0017535 , -0.00591398,  0.06101051], dtype=float32), array([0.23670827, 0.21131717, 0.55197453], dtype=float32)]\n",
      "allocation:  [0.1745908  0.17344001 0.52206045]\n",
      "if_o: 0.06122279\n",
      "\n",
      "i 300\n",
      "batch_loss: 103.44 \n",
      "\n",
      "sum:  2.98   max:  1.00\n",
      "condition:  101.01   total_loss:  103.99\n",
      "value:  [1.10349706 0.54662219 0.33408388]\n",
      "payment:  [array([0.08647284, 0.00457896, 0.00090275], dtype=float32), array([0.3243547 , 0.31541112, 0.36023414], dtype=float32)]\n",
      "allocation:  [0.42363173 0.36607632 0.17021444]\n",
      "if_o: 0.017896354\n",
      "\n",
      "i 400\n",
      "batch_loss: 103.10 \n",
      "\n",
      "sum:  2.98   max:  0.99\n",
      "condition:  99.93   total_loss:  102.91\n",
      "value:  [0.61424718 0.6281872  0.54806077]\n",
      "payment:  [array([0.00541006, 0.01306695, 0.02035496], dtype=float32), array([0.28272504, 0.27400598, 0.44326904], dtype=float32)]\n",
      "allocation:  [0.30803815 0.27819836 0.27216333]\n",
      "if_o: 0.026043093\n",
      "\n",
      "i 500\n",
      "batch_loss: 103.27 \n",
      "\n",
      "sum:  2.98   max:  0.99\n",
      "condition:  100.10   total_loss:  103.08\n",
      "value:  [0.60011222 0.66316414 0.59455134]\n",
      "payment:  [array([-0.00120075,  0.02363227,  0.03582011], dtype=float32), array([0.2768772 , 0.2709003 , 0.45222247], dtype=float32)]\n",
      "allocation:  [0.28384727 0.25669602 0.26784205]\n",
      "if_o: 0.021864237\n",
      "\n",
      "i 600\n",
      "batch_loss: 102.99 \n",
      "\n",
      "sum:  2.98   max:  0.99\n",
      "condition:  99.99   total_loss:  102.97\n",
      "value:  [0.59723323 0.54970964 0.47889162]\n",
      "payment:  [array([0.0258155 , 0.01119505, 0.01959787], dtype=float32), array([0.282459  , 0.28066456, 0.4368765 ], dtype=float32)]\n",
      "allocation:  [0.28015223 0.2546246  0.2554387 ]\n",
      "if_o: 0.022150215\n",
      "\n",
      "i 700\n",
      "batch_loss: 103.11 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  100.02   total_loss:  103.01\n",
      "value:  [0.87013267 0.56869333 0.191766  ]\n",
      "payment:  [array([0.02620792, 0.01071817, 0.00324291], dtype=float32), array([0.31982613, 0.32865718, 0.3515167 ], dtype=float32)]\n",
      "allocation:  [0.35318068 0.31017202 0.15460679]\n",
      "if_o: 0.014632071\n",
      "\n",
      "i 800\n",
      "batch_loss: 102.99 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  100.05   total_loss:  103.04\n",
      "value:  [0.94165352 0.28747019 0.70716337]\n",
      "payment:  [array([0.03126724, 0.00408285, 0.01890256], dtype=float32), array([0.25739312, 0.2552835 , 0.48732337], dtype=float32)]\n",
      "allocation:  [0.20361343 0.18516038 0.23390007]\n",
      "if_o: 0.009906151\n",
      "\n",
      "i 900\n",
      "batch_loss: 103.11 \n",
      "\n",
      "sum:  2.98   max:  0.99\n",
      "condition:  100.00   total_loss:  102.98\n",
      "value:  [0.43095372 0.56539789 0.37109186]\n",
      "payment:  [array([-0.00368936,  0.01519617,  0.00903826], dtype=float32), array([0.28191817, 0.28848398, 0.42959785], dtype=float32)]\n",
      "allocation:  [0.2609008  0.24027641 0.24090765]\n",
      "if_o: 0.022620259\n",
      "\n",
      "i 1000\n",
      "batch_loss: 103.00 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  99.95   total_loss:  102.94\n",
      "value:  [0.47311983 0.46153047 0.48043015]\n",
      "payment:  [array([0.00959996, 0.00837117, 0.01894663], dtype=float32), array([0.26501122, 0.26991796, 0.4650708 ], dtype=float32)]\n",
      "allocation:  [0.21907492 0.20520054 0.25557804]\n",
      "if_o: 0.019466834\n",
      "\n",
      "i 1100\n",
      "batch_loss: 103.02 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  100.05   total_loss:  103.04\n",
      "value:  [0.3566144  0.55353757 0.68487487]\n",
      "payment:  [array([0.00116653, 0.01196434, 0.03553568], dtype=float32), array([0.24596623, 0.24846219, 0.50557154], dtype=float32)]\n",
      "allocation:  [0.17818521 0.17182668 0.28547665]\n",
      "if_o: 0.018185306\n",
      "\n",
      "i 1200\n",
      "batch_loss: 103.03 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  99.97   total_loss:  102.96\n",
      "value:  [0.46950946 0.44265615 0.70430219]\n",
      "payment:  [array([0.00724556, 0.00418762, 0.01385005], dtype=float32), array([0.24389255, 0.24719946, 0.508908  ], dtype=float32)]\n",
      "allocation:  [0.16568919 0.15916093 0.26842025]\n",
      "if_o: 0.014800517\n",
      "\n",
      "i 1300\n",
      "batch_loss: 103.00 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  99.98   total_loss:  102.97\n",
      "value:  [0.55187925 0.63746659 0.61001196]\n",
      "payment:  [array([0.00555982, 0.00953841, 0.00823308], dtype=float32), array([0.26292896, 0.27419156, 0.4628795 ], dtype=float32)]\n",
      "allocation:  [0.20006752 0.18348756 0.20304614]\n",
      "if_o: 0.011150889\n",
      "\n",
      "i 1400\n",
      "batch_loss: 103.07 \n",
      "\n",
      "sum:  2.98   max:  0.99\n",
      "condition:  100.39   total_loss:  103.37\n",
      "value:  [0.34472552 0.20960578 0.22460459]\n",
      "payment:  [array([ 0.00068411, -0.01220859, -0.01308293], dtype=float32), array([0.26960066, 0.2776757 , 0.4527237 ], dtype=float32)]\n",
      "allocation:  [0.19701447 0.18873568 0.26159772]\n",
      "if_o: 0.02730374\n",
      "\n",
      "i 1500\n",
      "batch_loss: 103.05 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  99.99   total_loss:  102.99\n",
      "value:  [0.33893891 0.65084747 0.71856169]\n",
      "payment:  [array([-0.00251507,  0.01327854,  0.01584272], dtype=float32), array([0.24515134, 0.25379673, 0.50105196], dtype=float32)]\n",
      "allocation:  [0.15848683 0.15243874 0.24142839]\n",
      "if_o: 0.0135140065\n",
      "\n",
      "i 1600\n",
      "batch_loss: 102.98 \n",
      "\n",
      "sum:  2.99   max:  1.00\n",
      "condition:  99.99   total_loss:  102.98\n",
      "value:  [0.45202862 0.50309385 0.55116311]\n",
      "payment:  [array([ 0.00308658, -0.00089869,  0.01292726], dtype=float32), array([0.2567595 , 0.26961777, 0.4736228 ], dtype=float32)]\n",
      "allocation:  [0.17404999 0.16359445 0.2123432 ]\n",
      "if_o: 0.013101477\n",
      "\n",
      "i 1700\n",
      "batch_loss: 102.99 \n",
      "\n",
      "sum:  3.00   max:  1.00\n",
      "condition:  100.00   total_loss:  103.00\n",
      "value:  [0.60748012 0.54194947 0.67211842]\n",
      "payment:  [array([-0.0007261 ,  0.00489923,  0.02111302], dtype=float32), array([0.25568727, 0.27117723, 0.4731355 ], dtype=float32)]\n",
      "allocation:  [0.16054396 0.14823736 0.17911197]\n",
      "if_o: 0.008083523\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        h_loss, h_delay_sum, h_delay_max, h_condition, payment_R, allocation_R, if_o = net(\n",
    "            X_train[index_random])\n",
    "        denominator += 1\n",
    "        loss_sum += h_loss\n",
    "        \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"i\", i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss))\n",
    "        \n",
    "        \n",
    "        print()\n",
    "        print(\"sum:  %.2f\"% float(h_delay_sum),\"  max:  %.2f\"% float(h_delay_max) )\n",
    "        print(\"condition:  %.2f\"%h_condition, \"  total_loss:  %.2f\"% float(h_loss))\n",
    "        print(\"value: \", X_train[index_random])\n",
    "        print(\"payment: \", payment_R)\n",
    "        print(\"allocation: \", allocation_R)\n",
    "        print(\"if_o:\", if_o)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-22T06:33:08.998Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "loss_sum =0 \n",
    "sum_delay = 0\n",
    "max_delay = 0\n",
    "loss_condition =0 \n",
    "for j in range(100):\n",
    "    index_random = random.randint(0, len(X_test) - 1)\n",
    "    h_loss, h_delay_sum, h_delay_max, h_condition, payment_R, allocation_R, if_o = net(\n",
    "        X_test[index_random])\n",
    "    \n",
    "    denominator += 1\n",
    "    loss_sum += float (h_loss)\n",
    "    sum_delay += float (h_delay_sum)\n",
    "    max_delay += float (h_delay_max)\n",
    "    loss_condition +=float (h_condition)\n",
    "    print()\n",
    "    print(\"sum:\", float(h_delay_sum),\"  max:\", float(h_delay_max) )\n",
    "    if(h_condition<=1e-5):\n",
    "        print(\"condition:\",0, \"  total_loss:\", float(h_loss))\n",
    "    else:\n",
    "        print(\"condition:\",h_condition, \"  total_loss:\", float(h_loss))\n",
    "    print(\"value:\", X_train[index_random])\n",
    "    print(\"payment:\", payment_R)\n",
    "    print(\"allocation:\", allocation_R)\n",
    "    print(\"if_o:\", if_o)\n",
    "    #print(\"delay:\" , delay_R)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-22T06:33:08.999Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_3_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341.4px",
    "left": "535px",
    "right": "20px",
    "top": "92px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
