{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:55.060676Z",
     "start_time": "2021-03-24T02:57:53.124179Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import itertools\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:55.091593Z",
     "start_time": "2021-03-24T02:57:55.062670Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 3\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0\n",
    "Normal_loc2 = 1.5\n",
    "Normal_scale1 = 0.5\n",
    "Normal_scale2 = 0.5\n",
    "Distribution_number = 10000\n",
    "Multiple = 4\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "target = \"min_sum\" \n",
    "order = \"normal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:55.530420Z",
     "start_time": "2021-03-24T02:57:55.095582Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[0.87100255 0.47569352 0.59480744]\n",
      " [0.44580099 0.33341374 0.87415917]\n",
      " [0.81020599 0.64803864 0.50817324]]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "#exec(open('../distribution/twopeaknormal.py').read())\n",
    "exec(open('../../distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "for i in range(len(value_list)):\n",
    "    for j in range(len(value_list[0])):\n",
    "        if (value_list[i][j] <= 0):\n",
    "            value_list[i][j] = 0\n",
    "        if (value_list[i][j] >= 1):\n",
    "            value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:55.561335Z",
     "start_time": "2021-03-24T02:57:55.532415Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:57.282160Z",
     "start_time": "2021-03-24T02:57:55.565339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9938)\n",
      "tensor(0.4938)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:57.298152Z",
     "start_time": "2021-03-24T02:57:57.284154Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-9>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:57.376906Z",
     "start_time": "2021-03-24T02:57:57.299115Z"
    }
   },
   "outputs": [],
   "source": [
    "allBits = [torch.tensor(bits, dtype=torch.int16) for bits in itertools.product([0, 1], repeat=Agent_number_n * Multiple)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:57.424777Z",
     "start_time": "2021-03-24T02:57:57.378919Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n * Multiple\n",
    "        num_hidden = 20\n",
    "        num_output = Agent_number_n * Multiple\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "\n",
    "    def model(self, bits):\n",
    "        h1 = torch.relu_(self.hidden_0(bits))\n",
    "        # h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)  # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        payment = torch.sigmoid(h4)\n",
    "\n",
    "        return payment\n",
    "\n",
    "    def bitsToPayments(self, bits):\n",
    "        if torch.sum(bits).item() == 0:\n",
    "            return torch.ones(Agent_number_n * Multiple).cuda()\n",
    "        bits = bits.type(torch.float32).cuda()\n",
    "        negBits = torch.ones(Agent_number_n * Multiple).cuda() - bits\n",
    "        payments = self.model(bits)\n",
    "        payments = payments - 1000 * negBits\n",
    "        payments = torch.softmax(payments, 0)\n",
    "        payments = payments + negBits\n",
    "        return payments\n",
    "\n",
    "    def tpToBits(self, tp, bits=torch.ones(Agent_number_n * Multiple).type(torch.uint8).cuda()):\n",
    "        payments = self.bitsToPayments(bits)\n",
    "        \n",
    "#         print(tp)\n",
    "#         print(payments)\n",
    "#         print(tp >= payments)\n",
    "        \n",
    "        newBits = (tp >= payments).type(torch.uint8).cuda()\n",
    "        if torch.equal(newBits, bits):\n",
    "            return bits\n",
    "        else:\n",
    "            # bits-bits#tpToBits(tp, newBits)\n",
    "            return self.tpToBits(tp, newBits)\n",
    "\n",
    "    def tpToPayments(self, tp):\n",
    "        return self.bitsToPayments(self.tpToBits(tp))\n",
    "\n",
    "    def tpToTotalDelay(self, tp):\n",
    "        if(target == \"min_max\"):\n",
    "            print(\"not work\")\n",
    "            #return torch.max(torch.tensor(0.0), torch.dot(tp, self.tpToBits(tp).type(torch.float32))-1.0)\n",
    "        if(target == \"min_sum\"):\n",
    "            bat = torch.ones(Agent_number_n * Multiple).cuda()\n",
    "            for i in range(Agent_number_n):\n",
    "                bat[i*4] *=0.1\n",
    "                bat[i*4+1] *=0.2\n",
    "                bat[i*4+2] *=0.3\n",
    "                bat[i*4+3] *=0.4\n",
    "            return Agent_number_n - torch.sum(self.tpToBits(tp).type(torch.float32)* bat )\n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, value_list):\n",
    "\n",
    "        loss_condition = 0\n",
    "        loss_sum_delay = 0\n",
    "        loss_max_delay = 0\n",
    "        \n",
    "        for k in range(len(value_list)):\n",
    "            \n",
    "            value_multiple = []\n",
    "            for i in range(len(value_list[k])):\n",
    "                value_multiple.append(value_list[k][i]*0.1)\n",
    "                value_multiple.append(value_list[k][i]*0.2)\n",
    "                value_multiple.append(value_list[k][i]*0.3)\n",
    "                value_multiple.append(value_list[k][i]*0.4)\n",
    "                \n",
    "            for i in range(len(value_multiple)):\n",
    "                test = copy.deepcopy(value_multiple)\n",
    "                test_change = torch.from_numpy(\n",
    "                    np.array(test)).cuda().type(torch.float32)\n",
    "                tp_1 = test_change.clone()\n",
    "                tp_1[i] = 1\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "                offer = self.tpToPayments(tp_1)[i]\n",
    "  \n",
    "\n",
    "                Delay_1 = self.tpToTotalDelay(tp_1)\n",
    "                Delay_2 = self.tpToTotalDelay(tp_0)\n",
    "\n",
    "                temp = ((1.0 - cdf(offer, order)) * Delay_1 + cdf(\n",
    "                    offer, order) * Delay_2)\n",
    "                loss_sum_delay += temp/len(value_multiple)\n",
    "\n",
    "            penalty = 0\n",
    "            penaltyLambda = 10\n",
    "            \n",
    "            for jj in range(10):\n",
    "                index_random_1 = random.randint(0, len(allBits) - 1)\n",
    "                bitsMoreOnes = allBits[index_random_1]\n",
    "                for ii in range(Agent_number_n * Multiple):\n",
    "                    if bitsMoreOnes[i] == 1:\n",
    "                        bitsLessOnes = bitsMoreOnes.clone()\n",
    "                        bitsLessOnes[i] = 0\n",
    "                        penalty = penalty + torch.sum(\n",
    "                            torch.relu(\n",
    "                                self.bitsToPayments(bitsMoreOnes) -\n",
    "                                self.bitsToPayments(bitsLessOnes)\n",
    "                            )\n",
    "                        )\n",
    "            loss_condition += penalty * penaltyLambda\n",
    "\n",
    "\n",
    "        if(target == \"min_sum\"):\n",
    "            loss = loss_sum_delay + loss_condition * 10\n",
    "        if(target == \"min_max\"):\n",
    "            loss = loss_max_delay + loss_condition * 10\n",
    "        \n",
    "        return loss, loss_sum_delay, loss_max_delay, float(loss_condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T02:57:57.488608Z",
     "start_time": "2021-03-24T02:57:57.426773Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "net = torch.load(\"Deep_learning_with_deadline_3_1\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00002)\n",
    "\n",
    "batch_size = 8\n",
    "echo_number = 5001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.412044Z",
     "start_time": "2021-03-24T02:57:57.489605Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo:  0\n",
      "batch_loss: 1.73 \n",
      "\n",
      "sum:  1.73   max:  0.00\n",
      "condition:  0.00   total_loss:  1.73\n",
      "value:  [0.25574796 0.5886169  0.45940323]\n",
      "\n",
      "echo:  50\n",
      "batch_loss: 2.21 \n",
      "\n",
      "sum:  2.21   max:  0.00\n",
      "condition:  0.00   total_loss:  2.21\n",
      "value:  [0.48566182 0.7966565  0.43013118]\n",
      "\n",
      "echo:  100\n",
      "batch_loss: 1.42 \n",
      "\n",
      "sum:  1.42   max:  0.00\n",
      "condition:  0.00   total_loss:  1.42\n",
      "value:  [0.43885032 0.69933932 0.76038337]\n",
      "\n",
      "echo:  150\n",
      "batch_loss: 2.28 \n",
      "\n",
      "sum:  2.28   max:  0.00\n",
      "condition:  0.00   total_loss:  2.28\n",
      "value:  [0.50463917 0.3830953  0.59433671]\n",
      "\n",
      "echo:  200\n",
      "batch_loss: 2.89 \n",
      "\n",
      "sum:  2.89   max:  0.00\n",
      "condition:  0.00   total_loss:  2.89\n",
      "value:  [0.19001782 0.4865159  0.54811311]\n",
      "\n",
      "echo:  250\n",
      "batch_loss: 2.38 \n",
      "\n",
      "sum:  2.38   max:  0.00\n",
      "condition:  0.00   total_loss:  2.38\n",
      "value:  [0.73428754 0.6280574  0.43375936]\n",
      "\n",
      "echo:  300\n",
      "batch_loss: 1.22 \n",
      "\n",
      "sum:  1.22   max:  0.00\n",
      "condition:  0.00   total_loss:  1.22\n",
      "value:  [0.56123744 0.4497524  0.97797723]\n",
      "\n",
      "echo:  350\n",
      "batch_loss: 1.71 \n",
      "\n",
      "sum:  1.71   max:  0.00\n",
      "condition:  0.00   total_loss:  1.71\n",
      "value:  [0.10391726 0.55538946 0.28645944]\n",
      "\n",
      "echo:  400\n",
      "batch_loss: 2.53 \n",
      "\n",
      "sum:  2.53   max:  0.00\n",
      "condition:  0.00   total_loss:  2.53\n",
      "value:  [0.46171242 0.29218807 0.6300783 ]\n",
      "\n",
      "echo:  450\n",
      "batch_loss: 2.48 \n",
      "\n",
      "sum:  2.48   max:  0.00\n",
      "condition:  0.00   total_loss:  2.48\n",
      "value:  [0.32263967 0.22978168 0.44902127]\n",
      "\n",
      "echo:  500\n",
      "batch_loss: 2.06 \n",
      "\n",
      "sum:  2.06   max:  0.00\n",
      "condition:  0.00   total_loss:  2.06\n",
      "value:  [0.62954896 0.43578958 0.38115744]\n",
      "\n",
      "echo:  550\n",
      "batch_loss: 2.41 \n",
      "\n",
      "sum:  2.41   max:  0.00\n",
      "condition:  0.00   total_loss:  2.41\n",
      "value:  [0.3939297  0.61410571 0.60336856]\n",
      "\n",
      "echo:  600\n",
      "batch_loss: 2.38 \n",
      "\n",
      "sum:  2.38   max:  0.00\n",
      "condition:  0.00   total_loss:  2.38\n",
      "value:  [0.22787978 0.75964132 0.18664087]\n",
      "\n",
      "echo:  650\n",
      "batch_loss: 1.87 \n",
      "\n",
      "sum:  1.87   max:  0.00\n",
      "condition:  0.00   total_loss:  1.87\n",
      "value:  [0.65569489 0.82058993 0.38060363]\n",
      "\n",
      "echo:  700\n",
      "batch_loss: 1.70 \n",
      "\n",
      "sum:  1.70   max:  0.00\n",
      "condition:  0.00   total_loss:  1.70\n",
      "value:  [0.09296496 0.53743932 0.29664468]\n",
      "\n",
      "echo:  750\n",
      "batch_loss: 2.51 \n",
      "\n",
      "sum:  2.51   max:  0.00\n",
      "condition:  0.00   total_loss:  2.51\n",
      "value:  [0.48036302 0.69856734 0.27941819]\n",
      "\n",
      "echo:  800\n",
      "batch_loss: 2.56 \n",
      "\n",
      "sum:  2.56   max:  0.00\n",
      "condition:  0.00   total_loss:  2.56\n",
      "value:  [0.37253476 0.63189581 0.71271435]\n",
      "\n",
      "echo:  850\n",
      "batch_loss: 2.17 \n",
      "\n",
      "sum:  2.17   max:  0.00\n",
      "condition:  0.00   total_loss:  2.17\n",
      "value:  [0.73330843 0.63665698 0.50254857]\n",
      "\n",
      "echo:  900\n",
      "batch_loss: 2.45 \n",
      "\n",
      "sum:  2.45   max:  0.00\n",
      "condition:  0.00   total_loss:  2.45\n",
      "value:  [0.64243998 0.22716135 0.75735686]\n",
      "\n",
      "echo:  950\n",
      "batch_loss: 1.82 \n",
      "\n",
      "sum:  1.82   max:  0.00\n",
      "condition:  0.00   total_loss:  1.82\n",
      "value:  [0.56099993 0.72432208 0.8581717 ]\n",
      "\n",
      "echo:  1000\n",
      "batch_loss: 2.08 \n",
      "\n",
      "sum:  2.08   max:  0.00\n",
      "condition:  0.00   total_loss:  2.08\n",
      "value:  [0.61470592 0.62323506 0.5035405 ]\n",
      "\n",
      "echo:  1050\n",
      "batch_loss: 2.25 \n",
      "\n",
      "sum:  2.25   max:  0.00\n",
      "condition:  0.00   total_loss:  2.25\n",
      "value:  [0.66520424 0.85957356 0.39353913]\n",
      "\n",
      "echo:  1100\n",
      "batch_loss: 2.31 \n",
      "\n",
      "sum:  2.31   max:  0.00\n",
      "condition:  0.00   total_loss:  2.31\n",
      "value:  [0.59692496 0.52544984 0.61905606]\n",
      "\n",
      "echo:  1150\n",
      "batch_loss: 1.98 \n",
      "\n",
      "sum:  1.98   max:  0.00\n",
      "condition:  0.00   total_loss:  1.98\n",
      "value:  [0.69582235 0.64462667 0.51613189]\n",
      "\n",
      "echo:  1200\n",
      "batch_loss: 2.58 \n",
      "\n",
      "sum:  2.58   max:  0.00\n",
      "condition:  0.00   total_loss:  2.58\n",
      "value:  [0.98471376 0.47453489 0.35833093]\n",
      "\n",
      "echo:  1250\n",
      "batch_loss: 2.20 \n",
      "\n",
      "sum:  2.20   max:  0.00\n",
      "condition:  0.00   total_loss:  2.20\n",
      "value:  [0.23496648 0.45480619 0.80006376]\n",
      "\n",
      "echo:  1300\n",
      "batch_loss: 2.04 \n",
      "\n",
      "sum:  2.04   max:  0.00\n",
      "condition:  0.00   total_loss:  2.04\n",
      "value:  [0.31385239 0.45778054 0.24233387]\n",
      "\n",
      "echo:  1350\n",
      "batch_loss: 2.43 \n",
      "\n",
      "sum:  2.43   max:  0.00\n",
      "condition:  0.00   total_loss:  2.43\n",
      "value:  [0.43234422 0.64317652 0.93244916]\n",
      "\n",
      "echo:  1400\n",
      "batch_loss: 2.68 \n",
      "\n",
      "sum:  2.68   max:  0.00\n",
      "condition:  0.00   total_loss:  2.68\n",
      "value:  [0.17468351 0.34087997 0.48763904]\n",
      "\n",
      "echo:  1450\n",
      "batch_loss: 2.02 \n",
      "\n",
      "sum:  2.02   max:  0.00\n",
      "condition:  0.00   total_loss:  2.02\n",
      "value:  [0.50660575 0.75180921 0.70296935]\n",
      "\n",
      "echo:  1500\n",
      "batch_loss: 2.36 \n",
      "\n",
      "sum:  2.36   max:  0.00\n",
      "condition:  0.00   total_loss:  2.36\n",
      "value:  [0.31271418 0.26442922 0.48066138]\n",
      "\n",
      "echo:  1550\n",
      "batch_loss: 2.35 \n",
      "\n",
      "sum:  2.35   max:  0.00\n",
      "condition:  0.00   total_loss:  2.35\n",
      "value:  [0.19001782 0.4865159  0.54811311]\n",
      "\n",
      "echo:  1600\n",
      "batch_loss: 2.15 \n",
      "\n",
      "sum:  2.15   max:  0.00\n",
      "condition:  0.00   total_loss:  2.15\n",
      "value:  [0.53462582 0.42564932 0.4931427 ]\n",
      "\n",
      "echo:  1650\n",
      "batch_loss: 2.34 \n",
      "\n",
      "sum:  2.34   max:  0.00\n",
      "condition:  0.00   total_loss:  2.34\n",
      "value:  [0.64646657 0.2599464  0.55575202]\n",
      "\n",
      "echo:  1700\n",
      "batch_loss: 1.58 \n",
      "\n",
      "sum:  1.58   max:  0.00\n",
      "condition:  0.00   total_loss:  1.58\n",
      "value:  [0.91851883 0.64259766 0.38808069]\n",
      "\n",
      "echo:  1750\n",
      "batch_loss: 2.59 \n",
      "\n",
      "sum:  2.59   max:  0.00\n",
      "condition:  0.00   total_loss:  2.59\n",
      "value:  [0.54131479 0.30259816 0.26523224]\n",
      "\n",
      "echo:  1800\n",
      "batch_loss: 2.33 \n",
      "\n",
      "sum:  2.33   max:  0.00\n",
      "condition:  0.00   total_loss:  2.33\n",
      "value:  [0.76933702 0.2493214  0.48092041]\n",
      "\n",
      "echo:  1850\n",
      "batch_loss: 2.92 \n",
      "\n",
      "sum:  2.92   max:  0.00\n",
      "condition:  0.00   total_loss:  2.92\n",
      "value:  [0.5138104  0.33406089 0.38895849]\n",
      "\n",
      "echo:  1900\n",
      "batch_loss: 2.48 \n",
      "\n",
      "sum:  2.48   max:  0.00\n",
      "condition:  0.00   total_loss:  2.48\n",
      "value:  [0.38610555 0.78534423 0.5313688 ]\n",
      "\n",
      "echo:  1950\n",
      "batch_loss: 1.66 \n",
      "\n",
      "sum:  1.66   max:  0.00\n",
      "condition:  0.00   total_loss:  1.66\n",
      "value:  [0.30690189 0.50300467 0.62598758]\n",
      "\n",
      "echo:  2000\n",
      "batch_loss: 2.28 \n",
      "\n",
      "sum:  2.28   max:  0.00\n",
      "condition:  0.00   total_loss:  2.28\n",
      "value:  [0.18568755 0.92243141 0.35040463]\n",
      "\n",
      "echo:  2050\n",
      "batch_loss: 2.50 \n",
      "\n",
      "sum:  2.50   max:  0.00\n",
      "condition:  0.00   total_loss:  2.50\n",
      "value:  [0.56423068 0.42236936 0.71690875]\n",
      "\n",
      "echo:  2100\n",
      "batch_loss: 2.52 \n",
      "\n",
      "sum:  2.52   max:  0.00\n",
      "condition:  0.00   total_loss:  2.52\n",
      "value:  [0.54006081 0.75496646 0.20919157]\n",
      "\n",
      "echo:  2150\n",
      "batch_loss: 1.48 \n",
      "\n",
      "sum:  1.48   max:  0.00\n",
      "condition:  0.00   total_loss:  1.48\n",
      "value:  [0.41210118 0.71304804 0.59131274]\n",
      "\n",
      "echo:  2200\n",
      "batch_loss: 2.18 \n",
      "\n",
      "sum:  2.18   max:  0.00\n",
      "condition:  0.00   total_loss:  2.18\n",
      "value:  [0.37600533 0.8259605  0.53742208]\n",
      "\n",
      "echo:  2250\n",
      "batch_loss: 2.03 \n",
      "\n",
      "sum:  2.03   max:  0.00\n",
      "condition:  0.00   total_loss:  2.03\n",
      "value:  [0.752176   0.77489048 0.40637372]\n",
      "\n",
      "echo:  2300\n",
      "batch_loss: 1.98 \n",
      "\n",
      "sum:  1.98   max:  0.00\n",
      "condition:  0.00   total_loss:  1.98\n",
      "value:  [0.45287657 0.66465397 0.72955768]\n",
      "\n",
      "echo:  2350\n",
      "batch_loss: 2.44 \n",
      "\n",
      "sum:  2.44   max:  0.00\n",
      "condition:  0.00   total_loss:  2.44\n",
      "value:  [0.1624981  0.47793792 0.51356517]\n",
      "\n",
      "echo:  2400\n",
      "batch_loss: 1.58 \n",
      "\n",
      "sum:  1.58   max:  0.00\n",
      "condition:  0.00   total_loss:  1.58\n",
      "value:  [0.39580553 0.54194441 0.28440302]\n",
      "\n",
      "echo:  2450\n",
      "batch_loss: 2.14 \n",
      "\n",
      "sum:  2.14   max:  0.00\n",
      "condition:  0.00   total_loss:  2.14\n",
      "value:  [0.66252425 0.59525355 0.62134527]\n",
      "\n",
      "echo:  2500\n",
      "batch_loss: 2.71 \n",
      "\n",
      "sum:  2.71   max:  0.00\n",
      "condition:  0.00   total_loss:  2.71\n",
      "value:  [0.30890949 0.49145885 0.31116857]\n",
      "\n",
      "echo:  2550\n",
      "batch_loss: 1.81 \n",
      "\n",
      "sum:  1.81   max:  0.00\n",
      "condition:  0.00   total_loss:  1.81\n",
      "value:  [0.48271764 0.63119165 0.72025982]\n",
      "\n",
      "echo:  2600\n",
      "batch_loss: 1.65 \n",
      "\n",
      "sum:  1.65   max:  0.00\n",
      "condition:  0.00   total_loss:  1.65\n",
      "value:  [0.23658974 0.31909748 0.5588797 ]\n",
      "\n",
      "echo:  2650\n",
      "batch_loss: 2.21 \n",
      "\n",
      "sum:  2.21   max:  0.00\n",
      "condition:  0.00   total_loss:  2.21\n",
      "value:  [0.29482524 0.5073588  0.42826694]\n",
      "\n",
      "echo:  2700\n",
      "batch_loss: 2.16 \n",
      "\n",
      "sum:  2.16   max:  0.00\n",
      "condition:  0.00   total_loss:  2.16\n",
      "value:  [0.82020682 0.29956025 0.65263078]\n",
      "\n",
      "echo:  2750\n",
      "batch_loss: 1.37 \n",
      "\n",
      "sum:  1.37   max:  0.00\n",
      "condition:  0.00   total_loss:  1.37\n",
      "value:  [0.61632936 0.39241289 0.700612  ]\n",
      "\n",
      "echo:  2800\n",
      "batch_loss: 1.79 \n",
      "\n",
      "sum:  1.79   max:  0.00\n",
      "condition:  0.00   total_loss:  1.79\n",
      "value:  [0.52185399 0.68554289 0.68477847]\n",
      "\n",
      "echo:  2850\n",
      "batch_loss: 2.50 \n",
      "\n",
      "sum:  2.50   max:  0.00\n",
      "condition:  0.00   total_loss:  2.50\n",
      "value:  [0.8938882  0.54923347 0.16216469]\n",
      "\n",
      "echo:  2900\n",
      "batch_loss: 1.85 \n",
      "\n",
      "sum:  1.85   max:  0.00\n",
      "condition:  0.00   total_loss:  1.85\n",
      "value:  [0.59359328 0.75984643 0.4148862 ]\n",
      "\n",
      "echo:  2950\n",
      "batch_loss: 2.06 \n",
      "\n",
      "sum:  2.06   max:  0.00\n",
      "condition:  0.00   total_loss:  2.06\n",
      "value:  [0.29942268 0.39079528 0.86938337]\n",
      "\n",
      "echo:  3000\n",
      "batch_loss: 2.07 \n",
      "\n",
      "sum:  2.07   max:  0.00\n",
      "condition:  0.00   total_loss:  2.07\n",
      "value:  [0.31275224 0.70260035 0.33980013]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo:  3050\n",
      "batch_loss: 1.50 \n",
      "\n",
      "sum:  1.50   max:  0.00\n",
      "condition:  0.00   total_loss:  1.50\n",
      "value:  [0.7684736  0.68681957 0.50503231]\n",
      "\n",
      "echo:  3100\n",
      "batch_loss: 1.84 \n",
      "\n",
      "sum:  1.84   max:  0.00\n",
      "condition:  0.00   total_loss:  1.84\n",
      "value:  [0.82830463 0.68675293 0.38599474]\n",
      "\n",
      "echo:  3150\n",
      "batch_loss: 2.36 \n",
      "\n",
      "sum:  2.36   max:  0.00\n",
      "condition:  0.00   total_loss:  2.36\n",
      "value:  [0.49982192 0.14905514 0.7035316 ]\n",
      "\n",
      "echo:  3200\n",
      "batch_loss: 2.35 \n",
      "\n",
      "sum:  2.35   max:  0.00\n",
      "condition:  0.00   total_loss:  2.35\n",
      "value:  [0.33330239 0.19162812 0.28006944]\n",
      "\n",
      "echo:  3250\n",
      "batch_loss: 1.01 \n",
      "\n",
      "sum:  1.01   max:  0.00\n",
      "condition:  0.00   total_loss:  1.01\n",
      "value:  [0.79968014 0.5335649  0.898872  ]\n",
      "\n",
      "echo:  3300\n",
      "batch_loss: 2.37 \n",
      "\n",
      "sum:  2.37   max:  0.00\n",
      "condition:  0.00   total_loss:  2.37\n",
      "value:  [0.49544305 0.35628663 0.73915719]\n",
      "\n",
      "echo:  3350\n",
      "batch_loss: 2.18 \n",
      "\n",
      "sum:  2.18   max:  0.00\n",
      "condition:  0.00   total_loss:  2.18\n",
      "value:  [0.71496639 0.67634026 0.29197639]\n",
      "\n",
      "echo:  3400\n",
      "batch_loss: 2.27 \n",
      "\n",
      "sum:  2.27   max:  0.00\n",
      "condition:  0.00   total_loss:  2.27\n",
      "value:  [0.23321733 0.33112068 0.479742  ]\n",
      "\n",
      "echo:  3450\n",
      "batch_loss: 2.60 \n",
      "\n",
      "sum:  2.60   max:  0.00\n",
      "condition:  0.00   total_loss:  2.60\n",
      "value:  [0.76933702 0.2493214  0.48092041]\n",
      "\n",
      "echo:  3500\n",
      "batch_loss: 2.20 \n",
      "\n",
      "sum:  2.20   max:  0.00\n",
      "condition:  0.00   total_loss:  2.20\n",
      "value:  [0.4625675  0.45523711 0.26869558]\n",
      "\n",
      "echo:  3550\n",
      "batch_loss: 2.30 \n",
      "\n",
      "sum:  2.30   max:  0.00\n",
      "condition:  0.00   total_loss:  2.30\n",
      "value:  [0.98471376 0.47453489 0.35833093]\n",
      "\n",
      "echo:  3600\n",
      "batch_loss: 2.53 \n",
      "\n",
      "sum:  2.53   max:  0.00\n",
      "condition:  0.00   total_loss:  2.53\n",
      "value:  [0.38039356 0.72852998 0.25642185]\n",
      "\n",
      "echo:  3650\n",
      "batch_loss: 2.09 \n",
      "\n",
      "sum:  2.09   max:  0.00\n",
      "condition:  0.00   total_loss:  2.09\n",
      "value:  [0.73932281 0.45398944 0.7365394 ]\n",
      "\n",
      "echo:  3700\n",
      "batch_loss: 2.07 \n",
      "\n",
      "sum:  2.07   max:  0.00\n",
      "condition:  0.00   total_loss:  2.07\n",
      "value:  [0.42325452 0.30924543 0.60737649]\n",
      "\n",
      "echo:  3750\n",
      "batch_loss: 2.67 \n",
      "\n",
      "sum:  2.67   max:  0.00\n",
      "condition:  0.00   total_loss:  2.67\n",
      "value:  [0.47769045 0.68146425 0.4993211 ]\n",
      "\n",
      "echo:  3800\n",
      "batch_loss: 2.31 \n",
      "\n",
      "sum:  2.31   max:  0.00\n",
      "condition:  0.00   total_loss:  2.31\n",
      "value:  [0.67892627 0.42804278 0.360645  ]\n",
      "\n",
      "echo:  3850\n",
      "batch_loss: 2.23 \n",
      "\n",
      "sum:  2.23   max:  0.00\n",
      "condition:  0.00   total_loss:  2.23\n",
      "value:  [0.58918573 0.34565584 0.58248286]\n",
      "\n",
      "echo:  3900\n",
      "batch_loss: 2.53 \n",
      "\n",
      "sum:  2.53   max:  0.00\n",
      "condition:  0.00   total_loss:  2.53\n",
      "value:  [0.74277202 0.37283766 0.44410715]\n",
      "\n",
      "echo:  3950\n",
      "batch_loss: 2.00 \n",
      "\n",
      "sum:  2.00   max:  0.00\n",
      "condition:  0.00   total_loss:  2.00\n",
      "value:  [0.41658411 0.78879358 0.17345338]\n",
      "\n",
      "echo:  4000\n",
      "batch_loss: 1.43 \n",
      "\n",
      "sum:  1.43   max:  0.00\n",
      "condition:  0.00   total_loss:  1.43\n",
      "value:  [0.28473247 0.66408984 0.80897077]\n",
      "\n",
      "echo:  4050\n",
      "batch_loss: 1.59 \n",
      "\n",
      "sum:  1.59   max:  0.00\n",
      "condition:  0.00   total_loss:  1.59\n",
      "value:  [0.36160529 0.42248625 0.51649856]\n",
      "\n",
      "echo:  4100\n",
      "batch_loss: 2.12 \n",
      "\n",
      "sum:  2.12   max:  0.00\n",
      "condition:  0.00   total_loss:  2.12\n",
      "value:  [0.68519714 0.69445803 0.48067513]\n",
      "\n",
      "echo:  4150\n",
      "batch_loss: 2.53 \n",
      "\n",
      "sum:  2.53   max:  0.00\n",
      "condition:  0.00   total_loss:  2.53\n",
      "value:  [0.75081457 0.55242757 0.37403912]\n",
      "\n",
      "echo:  4200\n",
      "batch_loss: 2.38 \n",
      "\n",
      "sum:  2.38   max:  0.00\n",
      "condition:  0.00   total_loss:  2.38\n",
      "value:  [0.29791545 0.64155934 0.35543391]\n",
      "\n",
      "echo:  4250\n",
      "batch_loss: 2.03 \n",
      "\n",
      "sum:  2.03   max:  0.00\n",
      "condition:  0.00   total_loss:  2.03\n",
      "value:  [0.56794608 0.67361129 0.47643152]\n",
      "\n",
      "echo:  4300\n",
      "batch_loss: 1.08 \n",
      "\n",
      "sum:  1.08   max:  0.00\n",
      "condition:  0.00   total_loss:  1.08\n",
      "value:  [0.55492929 0.52509808 0.71102023]\n",
      "\n",
      "echo:  4350\n",
      "batch_loss: 1.04 \n",
      "\n",
      "sum:  1.04   max:  0.00\n",
      "condition:  0.00   total_loss:  1.04\n",
      "value:  [0.27215501 0.48682235 0.46255081]\n",
      "\n",
      "echo:  4400\n",
      "batch_loss: 2.17 \n",
      "\n",
      "sum:  2.17   max:  0.00\n",
      "condition:  0.00   total_loss:  2.17\n",
      "value:  [1.         0.54049713 0.88314072]\n",
      "\n",
      "echo:  4450\n",
      "batch_loss: 1.65 \n",
      "\n",
      "sum:  1.65   max:  0.00\n",
      "condition:  0.00   total_loss:  1.65\n",
      "value:  [0.63160417 0.68664873 0.62161658]\n",
      "\n",
      "echo:  4500\n",
      "batch_loss: 1.07 \n",
      "\n",
      "sum:  1.07   max:  0.00\n",
      "condition:  0.00   total_loss:  1.07\n",
      "value:  [0.64919075 0.73962573 0.44146732]\n",
      "\n",
      "echo:  4550\n",
      "batch_loss: 1.66 \n",
      "\n",
      "sum:  1.66   max:  0.00\n",
      "condition:  0.00   total_loss:  1.66\n",
      "value:  [0.38039356 0.72852998 0.25642185]\n",
      "\n",
      "echo:  4600\n",
      "batch_loss: 2.06 \n",
      "\n",
      "sum:  2.06   max:  0.00\n",
      "condition:  0.00   total_loss:  2.06\n",
      "value:  [0.65776318 0.6458245  0.5576083 ]\n",
      "\n",
      "echo:  4650\n",
      "batch_loss: 2.24 \n",
      "\n",
      "sum:  2.24   max:  0.00\n",
      "condition:  0.00   total_loss:  2.24\n",
      "value:  [0.21832471 0.67970459 0.57856281]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-27d750f0bb59>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mh_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_delay_sum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_delay_max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh_condition\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mh_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mdenominator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 722\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3bc74ecc3f73>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, value_list)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m                 \u001b[0mDelay_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpToTotalDelay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m                 \u001b[0mDelay_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpToTotalDelay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp_0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3bc74ecc3f73>\u001b[0m in \u001b[0;36mtpToTotalDelay\u001b[1;34m(self, tp)\u001b[0m\n\u001b[0;32m     71\u001b[0m                 \u001b[0mbat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m                 \u001b[0mbat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m                 \u001b[0mbat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m                 \u001b[0mbat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*=\u001b[0m\u001b[1;36m0.4\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mAgent_number_n\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtpToBits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m \u001b[0mbat\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for echo in range(int(echo_number)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for batch in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        X_train_list.append(X_train[index_random])\n",
    "        denominator += 1\n",
    "\n",
    "\n",
    "    h_loss, h_delay_sum, h_delay_max, h_condition = net(X_train_list)\n",
    "    \n",
    "    h_loss /= denominator\n",
    "    h_delay_sum /= denominator\n",
    "    h_delay_max /= denominator\n",
    "    h_condition /= denominator\n",
    "    \n",
    "    \n",
    "    loss = h_loss\n",
    "        \n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if echo % 50 == 0:\n",
    "        print(\"echo: \", echo)\n",
    "        print(\"batch_loss: %.2f \" % float(loss))\n",
    "        print()\n",
    "        print(\"sum:  %.2f\"% float(h_delay_sum),\"  max:  %.2f\"% float(h_delay_max) )\n",
    "        print(\"condition:  %.2f\"%h_condition, \"  total_loss:  %.2f\"% float(h_loss))\n",
    "        print(\"value: \", X_train[index_random])\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.412044Z",
     "start_time": "2021-03-24T02:57:53.094Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_with_deadline_3_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.412044Z",
     "start_time": "2021-03-24T02:57:53.096Z"
    }
   },
   "outputs": [],
   "source": [
    "denominator = 0\n",
    "loss_sum =0 \n",
    "sum_delay = 0\n",
    "max_delay = 0\n",
    "loss_condition =0 \n",
    "for j in range(100):\n",
    "    index_random = random.randint(0, len(X_test) - 1)\n",
    "    h_loss, h_delay_sum, h_delay_max, h_condition = net(\n",
    "        [X_test[index_random]])\n",
    "    \n",
    "    denominator += 1\n",
    "    loss_sum += float (h_loss)\n",
    "    sum_delay += float (h_delay_sum)\n",
    "    max_delay += float (h_delay_max)\n",
    "    loss_condition +=float (h_condition)\n",
    "    print()\n",
    "    print(\"sum:\", float(h_delay_sum),\"  max:\", float(h_delay_max) )\n",
    "    if(h_condition<=1e-5):\n",
    "        print(\"condition:\",0, \"  total_loss:\", float(h_loss))\n",
    "    else:\n",
    "        print(\"condition:\",h_condition, \"  total_loss:\", float(h_loss))\n",
    "    print(\"value:\", X_train[index_random])\n",
    "#     print(\"payment:\", payment_R)\n",
    "#     print(\"pay_time:\", pay_time_R)\n",
    "#     print(\"if_o:\", if_o)\n",
    "#     print(\"delay:\" , delay_R)\n",
    "    print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.412044Z",
     "start_time": "2021-03-24T02:57:53.097Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum / denominator))\n",
    "print(\"sum_delay:\", sum_delay/ denominator)\n",
    "print(\"max_delay:\", max_delay/ denominator)\n",
    "print(\"condition: %.2f \" % (loss_condition/ denominator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.416423Z",
     "start_time": "2021-03-24T02:57:53.099Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline_old(test, t_c, target):\n",
    "    temp_max_delay_list = [0 for i in range(len(test))]\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if (item + 1e-4 >= target / k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if (count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True\n",
    "            break\n",
    "        if (k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = sum(t_c)\n",
    "            result = False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result\n",
    "\n",
    "\n",
    "# Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay = 0\n",
    "    max_delay = 0\n",
    "    test_number = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number += 1\n",
    "        temp_max_delay = 0\n",
    "        temp_delay = 0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "\n",
    "        temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline_old(\n",
    "            test_change, copy.deepcopy(deadline_list), 1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change)\n",
    "            test_i = np.delete(test_i, j)\n",
    "\n",
    "            deadline_i = copy.deepcopy(deadline_list)\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "\n",
    "            temp_max_delay_i_list, temp_sum_delay_i, judge_i = cost_sharing_with_deadline_old(\n",
    "                test_i, deadline_i, 1.0)\n",
    "\n",
    "            if (judge_i == False):\n",
    "                temp_sum_delay += (1.0 - deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0 - deadline_list[j])\n",
    "\n",
    "        max_delay += max(temp_max_delay_list)\n",
    "\n",
    "        sum_delay += temp_sum_delay\n",
    "\n",
    "#     print(\"deadline: \", deadline_list)\n",
    "#     print(\"sum_delay: \", sum_delay / test_number)\n",
    "#     print(\"max_delay: \", max_delay / test_number)\n",
    "#     print()\n",
    "    return max_delay / test_number, sum_delay / test_number\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-24T05:05:20.417421Z",
     "start_time": "2021-03-24T02:57:53.101Z"
    }
   },
   "outputs": [],
   "source": [
    "list_1=[]\n",
    "list_2=[]\n",
    "list_3=[]\n",
    "for i in range(1,11):\n",
    "    x=float(i)/10\n",
    "    xx=[x for i in range(Agent_number_n)]\n",
    "    #print(xx)\n",
    "    res1,res2=run_cs_old(xx)\n",
    "    list_1.append(res1)\n",
    "    list_2.append(res2)\n",
    "    list_3.append(x)\n",
    "print(\"max_delay:\",min(list_1),\"deadline:\",list_3[list_1.index(min(list_1))])\n",
    "print(\"sum_dealy:\",min(list_2),\"deadline:\",list_3[list_2.index(min(list_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
