{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:18.701359Z",
     "start_time": "2021-03-08T09:34:51.910425Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:18.712327Z",
     "start_time": "2021-03-08T09:35:18.703316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 10\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0\n",
    "Normal_loc2 = 1.5\n",
    "Normal_scale1 = 0.5\n",
    "Normal_scale2 = 0.5\n",
    "Distribution_number = 10000\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "order = \"twopeaknormal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:20.578507Z",
     "start_time": "2021-03-08T09:35:18.715284Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[-0.38428031  0.38775843  0.70460685  0.26806146  0.81204556  1.70615276\n",
      "   0.40609494  1.39726561  1.98746029  1.36295156]\n",
      " [ 1.05479747  1.3018519   0.3671836   0.02031162  2.61557655  0.91898925\n",
      "   0.5343518  -0.26114839  0.73349509  1.45719937]\n",
      " [-0.32930356  2.00613951  0.36682569 -0.33268521 -0.18435603  0.48094871\n",
      "   1.15114868 -0.51760966 -0.19916007  0.26909097]]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../distribution/twopeaknormalwithoutlimit.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "# for i in range(len(value_list)):\n",
    "#     for j in range(len(value_list[0])):\n",
    "#         if (value_list[i][j] <= 0):\n",
    "#             value_list[i][j] = 0\n",
    "#         if (value_list[i][j] >= 1):\n",
    "#             value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:20.965916Z",
     "start_time": "2021-03-08T09:35:20.579516Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:31.938463Z",
     "start_time": "2021-03-08T09:35:20.966917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6979)\n",
      "tensor(0.4320)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:31.947529Z",
     "start_time": "2021-03-08T09:35:31.939402Z"
    }
   },
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return bits*0\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(Agent_number_n).cuda() - bits\n",
    "    paymentBits = negBits*1000\n",
    "\n",
    "    \n",
    "    cost_sharing_payment = 1.0/torch.sum(bits).item()\n",
    "\n",
    "    payments = bits * cost_sharing_payment\n",
    "    payments += paymentBits\n",
    "    \n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits):\n",
    "    payments = bitsToPayments(bits)\n",
    "    \n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    \n",
    "    if torch.sum(newBits).item() == 0:\n",
    "        return newBits\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "    \n",
    "def tpToTotalDelay(tp, deadline, _i):\n",
    "    ans = tpToBits(tp, torch.ones(Agent_number_n).type(torch.uint8).cuda())\n",
    "    if(torch.sum(ans).item()==0):\n",
    "        return torch.sum((1.0 - ans) * deadline), False\n",
    "    else:\n",
    "        return torch.sum((1.0 - ans) * deadline), True\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp,torch.ones(Agent_number_n).type(torch.uint8).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:31.962357Z",
     "start_time": "2021-03-08T09:35:31.949375Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-9>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:31.983590Z",
     "start_time": "2021-03-08T09:35:31.963337Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 50\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(Agent_number_n,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, value_list):\n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        # h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)  # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        deadline = torch.sigmoid((h4 + 1)*10)\n",
    "        # deadline = torch.sigmoid(self.deadline)\n",
    "        # print(deadline)\n",
    "        # return\n",
    "\n",
    "        Possible_i_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "\n",
    "            Possible = 0\n",
    "            for k in range(len(value_list)):\n",
    "                value_tensor = value_list[k]\n",
    "                test = copy.deepcopy(value_tensor)\n",
    "                test_change = copy.deepcopy(test)\n",
    "                test_change = deadline * test_change\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "\n",
    "                judge_i = tpToTotalDelay(tp_0, deadline, i)[1]\n",
    "                \n",
    "#                 temp_max_delay_list,temp_sum_delay,judge_ii =  cost_sharing_with_deadline(tp_0,\n",
    "#                         deadline,1.0)\n",
    "#                 if (judge_i != judge_ii):\n",
    "#                     print(\"false\")\n",
    "#                     return\n",
    "                \n",
    "                \n",
    "                if (judge_i == True):\n",
    "                    Possible = Possible + 1.0/len(value_list)\n",
    "\n",
    "            Possible_i_list.append(Possible)\n",
    "\n",
    "        temp_sum_delay_total = torch.zeros(1).cuda()\n",
    "        temp_max_delay_total = torch.zeros(1).cuda()\n",
    "\n",
    "#         print(\"deadline:\",deadline)\n",
    "\n",
    "\n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            test_change = copy.deepcopy(test)\n",
    "            test_change = deadline * test_change\n",
    "\n",
    "            temp_sum_delay = 0\n",
    "            temp_max_delay = 0\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                tp_1 = test_change.clone()\n",
    "                tp_1[i] = 1\n",
    "                # tp_0 = copy.deepcopy(test_change_i)\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "                offer = tpToPayments(tp_1)[i]\n",
    "\n",
    "                Delay_1 = tpToTotalDelay(tp_1, deadline, i)[0]\n",
    "                Delay_2 = tpToTotalDelay(tp_0, deadline, i)[0]\n",
    "\n",
    "                temp = ((1.0 - cdf(offer/deadline[i], order)) * Delay_1 + cdf(\n",
    "                    offer/deadline[i], order) * Delay_2)/Agent_number_n\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "#                 print(\"test_change\",test_change)\n",
    "                \n",
    "#                 print(\"offer\",offer,cdf(offer/deadline[i], order))\n",
    "#                 print(\"temp\",temp)\n",
    "#                 print(\"Delay_1\", Delay_1)\n",
    "#                 print(\"Delay_2\", Delay_2)\n",
    "\n",
    "#                 print()\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "#             print(\"test_change\",test_change)\n",
    "#             print(\"deadline\",deadline)\n",
    "#             print(\"offer\",offer)\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "\n",
    "#             return\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                Possible = Possible_i_list[i]\n",
    "\n",
    "                temp = (1.0-deadline[i].clone()) * \\\n",
    "                    torch.tensor(1.0-Possible).cuda()\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "            temp_sum_delay_total = temp_sum_delay_total + temp_sum_delay\n",
    "            temp_sum_delay_total += torch.sum(-deadline)/1000\n",
    "\n",
    "        return temp_max_delay_total, temp_sum_delay_total, deadline.cpu(\n",
    "        ).data.numpy(), float(temp_sum_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:32.151955Z",
     "start_time": "2021-03-08T09:35:31.984276Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "net = torch.load(\"Deep_learning_with_deadline_10\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00002)\n",
    "\n",
    "batch_size = 32\n",
    "echo = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:36.667143Z",
     "start_time": "2021-03-08T09:35:32.154625Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch_loss: 5.02 \n",
      "value: [0.14116379758217978, 1.9415289125209885, 1.80249154079427, 0.26892215948374043, 0.9987225785413463, 0.3294269082340344, 2.1579798248761346, 1.9452793441148746, 0.3331298904210589, 1.2051826593491899]\n",
      "deadline: [4.1195452e-03 1.0299924e-03 5.9192136e-08 4.6514045e-03 4.2964150e-11\n",
      " 2.7833923e-03 9.9999940e-01 3.1113697e-07 9.7220987e-01 3.6621304e-06]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        X_train_list.append(\n",
    "            torch.from_numpy(np.array(X_train[index_random])).cuda().type(torch.float32))\n",
    "        denominator += 1\n",
    "\n",
    "    h_delay_max, h_delay_sum, deadline_R, delay_R = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"i\", i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum / denominator))\n",
    "        print(\"value:\", X_train[index_random])\n",
    "        print(\"deadline:\", deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:36.674125Z",
     "start_time": "2021-03-08T09:35:36.668141Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 5.02 \n",
      "value: [0.14116379758217978, 1.9415289125209885, 1.80249154079427, 0.26892215948374043, 0.9987225785413463, 0.3294269082340344, 2.1579798248761346, 1.9452793441148746, 0.3331298904210589, 1.2051826593491899]\n",
      "deadline: [4.1195452e-03 1.0299924e-03 5.9192136e-08 4.6514045e-03 4.2964150e-11\n",
      " 2.7833923e-03 9.9999940e-01 3.1113697e-07 9.7220987e-01 3.6621304e-06]\n",
      "delay: 4.745648384094238\n"
     ]
    }
   ],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum / denominator))\n",
    "print(\"value:\", X_train[index_random])\n",
    "print(\"deadline:\", deadline_R)\n",
    "print(\"delay:\", delay_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:43.813297Z",
     "start_time": "2021-03-08T09:35:36.676120Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.687685895767156, 3.4043355049378077)\n"
     ]
    }
   ],
   "source": [
    "def cost_sharing_with_deadline_old(test, t_c, target):\n",
    "    temp_max_delay_list = [0 for i in range(len(test))]\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if (item + 1e-4 >= target / k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if (count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True\n",
    "            break\n",
    "        if (k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = sum(t_c)\n",
    "            result = False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result\n",
    "\n",
    "\n",
    "# Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay = 0\n",
    "    max_delay = 0\n",
    "    test_number = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number += 1\n",
    "        temp_max_delay = 0\n",
    "        temp_delay = 0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "\n",
    "        temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline_old(\n",
    "            test_change, copy.deepcopy(deadline_list), 1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change)\n",
    "            test_i = np.delete(test_i, j)\n",
    "\n",
    "            deadline_i = copy.deepcopy(deadline_list)\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "\n",
    "            temp_max_delay_i_list, temp_sum_delay_i, judge_i = cost_sharing_with_deadline_old(\n",
    "                test_i, deadline_i, 1.0)\n",
    "\n",
    "            if (judge_i == False):\n",
    "                temp_sum_delay += (1.0 - deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0 - deadline_list[j])\n",
    "\n",
    "        max_delay += max(temp_max_delay_list)\n",
    "\n",
    "        sum_delay += temp_sum_delay\n",
    "\n",
    "#     print(\"deadline: \", deadline_list)\n",
    "#     print(\"sum_delay: \", sum_delay / test_number)\n",
    "#     print(\"max_delay: \", max_delay / test_number)\n",
    "#     print()\n",
    "    return max_delay / test_number, sum_delay / test_number\n",
    "\n",
    "\n",
    "print(run_cs_old(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:43.948639Z",
     "start_time": "2021-03-08T09:35:43.814320Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_with_deadline_10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:35:44.984016Z",
     "start_time": "2021-03-08T09:35:43.951321Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (0.6815537041522562, 3.491488046313048)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Foo(object):\n",
    "\n",
    "    def __init__(self, test_item, test_change_item, deadline):\n",
    "        self.test_item = test_item\n",
    "        self.test_change_item = test_change_item\n",
    "        self.deadline = deadline\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.test_change_item < other.test_change_item\n",
    "def cost_sharing_with_deadline_free(n,_i,numbers_of_people_will_pay,started_k):\n",
    "    \n",
    "    for k in range(started_k,0,-1):\n",
    "        if(n-_i<=k):\n",
    "            x=k-1\n",
    "        else:\n",
    "            x=k\n",
    "        #print(n,_i,x,numbers_of_people_will_pay[x],k)\n",
    "        if(numbers_of_people_will_pay[x]>=k):\n",
    "            return True,k\n",
    "    return False,0\n",
    "#Cost Sharing\n",
    "def run_cs_test(deadline_list):\n",
    "    sum_delay=0\n",
    "    max_delay=0\n",
    "    test_number=0\n",
    "    seconds_start=time.time()\n",
    "    for i in range(len(X_test)):\n",
    "#        if(i%1000==0):\n",
    "#            seconds=time.time()\n",
    "#            print(\"times: \",seconds-seconds_start)\n",
    "        test_number+=1\n",
    "        temp_max_delay=0\n",
    "        temp_delay=0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change_temp = []\n",
    "        Foo_list = []\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        \n",
    "        for j in range(len(test)):\n",
    "            test_change_temp.append(test[j] * deadline_list[j])\n",
    "            Foo_list.append(Foo(test[j],test_change_temp[j],deadline_list[j]))\n",
    "            \n",
    "        Foo_list.sort(reverse=False)\n",
    "        \n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test[j]=Foo_list[j].test_item\n",
    "            test_change_temp[j]=Foo_list[j].test_change_item\n",
    "            deadline_list[j]=Foo_list[j].deadline\n",
    "\n",
    "        test_change = copy.deepcopy(test_change_temp);\n",
    "        \n",
    "        numbers_of_people_will_pay = [-10 for ii in range(len(test_change)+2)]#pay 1/k\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        k = 1\n",
    "        started=len(test_change)-1\n",
    "        end_k=-10\n",
    "        for j in range(len(test_change)):\n",
    "            if(k<=len(test_change)):\n",
    "                for people_id in range(started,-1,-1):\n",
    "                    if(test_change[people_id]+1e-9>=1.0/k):\n",
    "                        started=people_id\n",
    "                        numbers_of_people_will_pay[k]=len(test_change)-people_id\n",
    "                        end_k=len(test_change)-people_id\n",
    "                    else:\n",
    "                        k+=1\n",
    "                        break;\n",
    "                    \n",
    "        for j in range(k,len(test_change)+1):\n",
    "            numbers_of_people_will_pay[j]=end_k\n",
    "            \n",
    "        deadlist_new=copy.deepcopy(deadline_list)\n",
    "        \n",
    "        temp_max_delay_list,temp_sum_delay,judge_i =  cost_sharing_with_deadline(test_change,\n",
    "                        deadlist_new,1.0)\n",
    "        \n",
    "        judge_i= True\n",
    "        started_k = len(test)\n",
    "        for _i in range(len(test_change)):\n",
    "            if judge_i:\n",
    "                judge_i,started_k =  cost_sharing_with_deadline_free(len(test_change),\n",
    "                    _i,numbers_of_people_will_pay,started_k)\n",
    "                \n",
    "                \n",
    "            started_k+=1\n",
    "            if(judge_i==False):\n",
    "                temp_sum_delay += (1.0-deadline_list[_i])\n",
    "                temp_max_delay_list[_i] += (1.0-deadline_list[_i])\n",
    "        \n",
    "        max_delay+=max(temp_max_delay_list)\n",
    "        \n",
    "        sum_delay+=temp_sum_delay\n",
    "        \n",
    "                \n",
    "    #print(\"max_delay\",max_delay/test_number);\n",
    "                \n",
    "\n",
    "    return max_delay/test_number,sum_delay/test_number\n",
    "\n",
    "    \n",
    "print(\"test:\",run_cs_test(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:36:35.313243Z",
     "start_time": "2021-03-08T09:35:44.985585Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay: 0.4243199999999746 deadline: 0.35\n",
      "sum_dealy: 1.9469279999999847 deadline: 0.43\n"
     ]
    }
   ],
   "source": [
    "list_1=[]\n",
    "list_2=[]\n",
    "list_3=[]\n",
    "for i in range(1,101):\n",
    "    x=float(i)/100\n",
    "    xx=[x for i in range(Agent_number_n)]\n",
    "    #print(xx)\n",
    "    res1,res2=run_cs_test(xx)\n",
    "    list_1.append(res1)\n",
    "    list_2.append(res2)\n",
    "    list_3.append(x)\n",
    "print(\"max_delay:\",min(list_1),\"deadline:\",list_3[list_1.index(min(list_1))])\n",
    "print(\"sum_dealy:\",min(list_2),\"deadline:\",list_3[list_2.index(min(list_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:36:41.382745Z",
     "start_time": "2021-03-08T09:36:35.315242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 2.0482 one_deadline: 1.9469279999999847\n",
      "NN: 2.0446 one_deadline: 1.9469279999999847\n",
      "105.0167%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "\n",
    "xx = [0 for i in range(Agent_number_n)]\n",
    "for i in range(int ((Agent_number_n+1)/2)):\n",
    "    xx[i]=1\n",
    "print(\"NN:\",run_cs_old(xx)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"NN:\",run_cs_test(xx)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(xx)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:36:49.785826Z",
     "start_time": "2021-03-08T09:36:41.383743Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 3.4597358798421287 one_deadline: 1.9469279999999847\n",
      "179.2200%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-08T09:36:58.085241Z",
     "start_time": "2021-03-08T09:36:49.786823Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay\n",
      "NN: 0.6838212624923327 one_deadline: 0.4243199999999746\n",
      "160.5287%\n"
     ]
    }
   ],
   "source": [
    "print(\"max_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[0],\"one_deadline:\",min(list_1))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[0]/min(list_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341.4px",
    "left": "535px",
    "right": "20px",
    "top": "92px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
