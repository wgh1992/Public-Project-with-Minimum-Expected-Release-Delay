{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:13.067014Z",
     "start_time": "2021-03-07T05:31:11.515548Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ComputerSoftwares\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:143: FutureWarning: The sklearn.datasets.samples_generator module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.datasets. Anything that cannot be imported from sklearn.datasets is now part of the private API.\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn.functional\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as opt\n",
    "from torch.autograd import Variable\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import scipy.stats as st\n",
    "from sklearn.datasets.samples_generator import make_blobs\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm as cm\n",
    "import torch.distributions as D\n",
    "import torch.nn.functional as F\n",
    "from scipy.interpolate import griddata\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    dev = \"cuda:0\"\n",
    "else:\n",
    "    dev = \"cpu\"\n",
    "print(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:13.078155Z",
     "start_time": "2021-03-07T05:31:13.068175Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.40058530825361593\n"
     ]
    }
   ],
   "source": [
    "# global veriable\n",
    "Uniform_low_bound = 0\n",
    "Uniform_up_bound = 1\n",
    "Agent_number_n = 5\n",
    "number_of_groups = 2\n",
    "Normal_loc = 0.5\n",
    "Normal_scale = 0.2\n",
    "Normal_loc1 = 0\n",
    "Normal_loc2 = 1.5\n",
    "Normal_scale1 = 0.5\n",
    "Normal_scale2 = 0.5\n",
    "Distribution_number = 10000\n",
    "\n",
    "beta_a = 0.3\n",
    "beta_b = 0.2\n",
    "cauchyloc = 1.0/Agent_number_n\n",
    "cauchyscalen = 0.004\n",
    "kumaraswamy_a = beta_a\n",
    "kumaraswamy_b = (1.0 + (beta_a - 1.0) * math.pow(\n",
    "    (beta_a + beta_b - 2.0) / (beta_a - 1.0), beta_a)) / beta_a\n",
    "print(kumaraswamy_b)\n",
    "\n",
    "independentnormalloc1 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(Agent_number_n, 0, -1)]\n",
    "independentnormalscale1 = [0.05 for ii in range(Agent_number_n)]\n",
    "\n",
    "independentnormalloc2 = [(float(ii) + 1) / (2 * Agent_number_n + 1)\n",
    "                         for ii in range(1, Agent_number_n + 1, 1)]\n",
    "independentnormalscale2 = [0.05 for ii in range(Agent_number_n)]\n",
    "exponentialhigh = 15  #Symbol(\"b\", real=True)\n",
    "exponentiallow = 15  #Symbol(\"a\", real=True)\n",
    "\n",
    "\n",
    "order = \"twopeaknormal\"\n",
    "# \"twopeak\",\"normal\",\"uniform\",\"independent1\",\"independent2\",\"cauchy\",\"beta\",\"U-exponential\",\"arcsine\"\n",
    "order1name = [\"dp\", \"random initializing\", \"costsharing\", \"heuristic\"]\n",
    "# \"costsharing\",\"dp\",\"heuristic\",\"random initializing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:14.252920Z",
     "start_time": "2021-03-07T05:31:13.081140Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n",
      "[[-0.54075137  0.90906491  1.29109189  0.78386954 -0.59334917]\n",
      " [ 1.28114709  1.82504991  1.80545656 -0.54939817 -0.87342519]\n",
      " [-0.10760487  0.08323954  0.22462387 -0.42767563  0.21373625]]\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# exec(open('distribution/twopeak.py').read())\n",
    "exec(open('../distribution/twopeaknormalwithoutlimit.py').read())\n",
    "# exec(open('distribution/normal.py').read())\n",
    "X_train, X_test = train_test_split(value_list,\n",
    "                                   test_size=0.5,\n",
    "                                   random_state=seed)\n",
    "# for i in range(len(value_list)):\n",
    "#     for j in range(len(value_list[0])):\n",
    "#         if (value_list[i][j] <= 0):\n",
    "#             value_list[i][j] = 0\n",
    "#         if (value_list[i][j] >= 1):\n",
    "#             value_list[i][j] = 1\n",
    "\n",
    "value_list1 = np.array(value_list)\n",
    "for i in range(min(Agent_number_n, 1)):\n",
    "    pa = value_list1[:, i]\n",
    "    plt.hist(pa, bins=200)\n",
    "    plt.show()\n",
    "\n",
    "dataset_size = len(X_train)\n",
    "print(dataset_size)\n",
    "print(np.array(X_train[:3]))\n",
    "print(len(X_test))\n",
    "# run_cs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:14.269900Z",
     "start_time": "2021-03-07T05:31:14.253917Z"
    }
   },
   "outputs": [],
   "source": [
    "d1 = D.normal.Normal(Normal_loc1, Normal_scale1)\n",
    "d2 = D.normal.Normal(Normal_loc2, Normal_scale2)\n",
    "distributionRatio1 = (d1.cdf(1) + d2.cdf(1) - d1.cdf(0) - d2.cdf(0)) / 2\n",
    "distributionBase1 = d1.cdf(0) + d2.cdf(0)\n",
    "\n",
    "d3 = D.normal.Normal(Normal_loc, Normal_scale)\n",
    "distributionRatio3 = d3.cdf(1) - d3.cdf(0)\n",
    "distributionBase3 = d3.cdf(0)\n",
    "\n",
    "d4 = D.uniform.Uniform(0.0, 1.0)\n",
    "distributionRatio4 = d4.cdf(1) - d4.cdf(0)\n",
    "distributionBase4 = d4.cdf(0)\n",
    "\n",
    "d5 = [\n",
    "    D.normal.Normal(independentnormalloc1[ii], independentnormalscale1[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "d6 = [\n",
    "    D.normal.Normal(independentnormalloc2[ii], independentnormalscale2[ii])\n",
    "    for ii in range(Agent_number_n)\n",
    "]\n",
    "\n",
    "d7 = D.cauchy.Cauchy(cauchyloc, cauchyscalen)\n",
    "d81 = D.exponential.Exponential(exponentiallow)\n",
    "d82 = D.exponential.Exponential(exponentialhigh)\n",
    "\n",
    "d9 = D.beta.Beta(beta_a, beta_b)\n",
    "d10 = D.beta.Beta(0.5, 0.5)\n",
    "\n",
    "\n",
    "def cdf(x, y, i=None):\n",
    "    if (y == \"twopeaknormal\"):\n",
    "        return (d1.cdf(x) + d2.cdf(x) ) / 2 #/ distributionRatio1\n",
    "    elif (y == \"normal\"):\n",
    "        return (d3.cdf(x) - distributionBase3) #/ distributionRatio3\n",
    "    elif (y == \"uniform\"):\n",
    "        return (d4.cdf(x) - distributionBase4) #/ distributionRatio4\n",
    "    elif (y == \"independent1\"):\n",
    "        return d5[i].cdf(x)\n",
    "    elif (y == \"independent2\"):\n",
    "        return d6[i].cdf(x)\n",
    "    elif (y == \"cauchy\"):\n",
    "        return d7.cdf(x)\n",
    "    elif (y == \"beta\"):\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            return 1.0 - torch.pow(1.0 - torch.pow(x, kumaraswamy_a),\n",
    "                                   kumaraswamy_b)\n",
    "        except:\n",
    "            return 1.0 - torch.pow(\n",
    "                1.0 - torch.pow(torch.tensor(x, dtype=torch.float32),\n",
    "                                kumaraswamy_a), kumaraswamy_b)\n",
    "    elif (y == \"arcsine\"):\n",
    "        #\n",
    "        if (x < 0.0000001):\n",
    "            x = 0.0000001\n",
    "        elif (x > 0.9999999):\n",
    "            x = 0.9999999\n",
    "        try:\n",
    "            res = 2.0 / math.pi * torch.asin(torch.sqrt(x))\n",
    "            # print(x)\n",
    "            return res  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "        except:\n",
    "            return 2.0 / math.pi * torch.asin(\n",
    "                torch.sqrt(torch.tensor(\n",
    "                    x, dtype=torch.float32)))  # + 0.0001*1.0/(\n",
    "            # math.pi * torch.sqrt(torch.tensor(x)*torch.tensor(1.0-x)))\n",
    "    elif (y == \"U-exponential\"):\n",
    "        return (d81.cdf(x) + (1.0 - d82.cdf(1.0 - x))) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:15.922593Z",
     "start_time": "2021-03-07T05:31:14.273864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6979)\n",
      "tensor(0.4320)\n"
     ]
    }
   ],
   "source": [
    "x=torch.nn.Parameter(torch.tensor(0.2,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "print(cdf(1.3717421124828532235939643347051, order))\n",
    "\n",
    "print(cdf(0.5, order))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:15.934587Z",
     "start_time": "2021-03-07T05:31:15.924590Z"
    }
   },
   "outputs": [],
   "source": [
    "def bitsToPayments(bits):\n",
    "    if torch.sum(bits).item() == 0:\n",
    "        return bits*0\n",
    "    bits = bits.type(torch.float32)\n",
    "    negBits = torch.ones(Agent_number_n).cuda() - bits\n",
    "    paymentBits = negBits*1000\n",
    "\n",
    "    \n",
    "    cost_sharing_payment = 1.0/torch.sum(bits).item()\n",
    "\n",
    "    payments = bits * cost_sharing_payment\n",
    "    payments += paymentBits\n",
    "    \n",
    "    return payments\n",
    "\n",
    "\n",
    "def tpToBits(tp, bits):\n",
    "    payments = bitsToPayments(bits)\n",
    "    \n",
    "    newBits = (tp >= payments).type(torch.uint8)\n",
    "    \n",
    "    \n",
    "    if torch.sum(newBits).item() == 0:\n",
    "        return newBits\n",
    "    \n",
    "    if torch.equal(newBits, bits):\n",
    "        return bits\n",
    "    else:\n",
    "        return tpToBits(tp, newBits)\n",
    "\n",
    "\n",
    "    \n",
    "def tpToTotalDelay(tp, deadline, _i):\n",
    "    ans = tpToBits(tp, torch.ones(Agent_number_n).type(torch.uint8).cuda())\n",
    "    if(torch.sum(ans).item()==0):\n",
    "        return torch.sum((1.0 - ans) * deadline), False\n",
    "    else:\n",
    "        return torch.sum((1.0 - ans) * deadline), True\n",
    "\n",
    "\n",
    "def tpToPayments(tp):\n",
    "    return bitsToPayments(tpToBits(tp,torch.ones(Agent_number_n).type(torch.uint8).cuda()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:15.950573Z",
     "start_time": "2021-03-07T05:31:15.936556Z"
    }
   },
   "outputs": [],
   "source": [
    "def cost_sharing_with_deadline(test,t_c,target):\n",
    "    temp_max_delay_list=[0 for i in range(len(test))]\n",
    "    temp_sum_delay=0\n",
    "    result=False\n",
    "    for k in range(len(test),0,-1):\n",
    "        count=0;\n",
    "        delay=0;\n",
    "        for ii in range(len(test)):\n",
    "            item= test[ii]\n",
    "            if(item+1e-9>=target/k):\n",
    "                count+=1;\n",
    "            else:\n",
    "                delay+=t_c[ii];\n",
    "                temp_max_delay_list[ii]=t_c[ii]\n",
    "            \n",
    "        if(count>=k):\n",
    "            temp_sum_delay+=delay;\n",
    "            result=True\n",
    "            break;\n",
    "        if(k<=1):\n",
    "            #print(test,number_n);\n",
    "            temp_max_delay_list=t_c\n",
    "            temp_sum_delay=sum(t_c);\n",
    "            result=False\n",
    "            \n",
    "    return temp_max_delay_list,temp_sum_delay,result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:15.968545Z",
     "start_time": "2021-03-07T05:31:15.951569Z"
    }
   },
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "    if isinstance(m, torch.nn.Conv2d):\n",
    "        torch.nn.init.xavier_normal_(m.weight,\n",
    "                                     gain=nn.init.calculate_gain('relu'))\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "    elif isinstance(m, torch.nn.Linear):\n",
    "        torch.nn.init.xavier_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        num_input = Agent_number_n\n",
    "        num_hidden = 50\n",
    "        num_output = Agent_number_n\n",
    "\n",
    "        self.hidden_0 = torch.nn.Linear(num_input, num_hidden)\n",
    "        self.hidden_1 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.hidden_2 = torch.nn.Linear(num_hidden, num_hidden)\n",
    "        self.output = torch.nn.Linear(num_hidden, num_output)\n",
    "        self.deadline = torch.nn.Parameter(torch.ones(Agent_number_n,\n",
    "                                                      requires_grad=True),\n",
    "                                           requires_grad=True).cuda()\n",
    "\n",
    "    def forward(self, value_list):\n",
    "        tensor = torch.ones(Agent_number_n, requires_grad=True)\n",
    "        variable = Variable(tensor, requires_grad=True)\n",
    "\n",
    "        h1 = torch.relu_(self.hidden_0(variable.cuda()))\n",
    "        # h1 = torch.relu_(self.hidden_0(value_tensor))\n",
    "        h2 = torch.relu_(self.hidden_1(h1))\n",
    "        h3 = torch.relu_(self.hidden_2(h2))\n",
    "        h4 = self.output(h3)  # no relu!!!!\n",
    "        # torch.sigmoid(self.deadline)# need more layer\n",
    "        deadline = torch.sigmoid((h4 + 1)*10)\n",
    "        # deadline = torch.sigmoid(self.deadline)\n",
    "        # print(deadline)\n",
    "        # return\n",
    "\n",
    "        Possible_i_list = []\n",
    "        for i in range(Agent_number_n):\n",
    "\n",
    "            Possible = 0\n",
    "            for k in range(len(value_list)):\n",
    "                value_tensor = value_list[k]\n",
    "                test = copy.deepcopy(value_tensor)\n",
    "                test_change = copy.deepcopy(test)\n",
    "                test_change = deadline * test_change\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "\n",
    "                judge_i = tpToTotalDelay(tp_0, deadline, i)[1]\n",
    "                \n",
    "#                 temp_max_delay_list,temp_sum_delay,judge_ii =  cost_sharing_with_deadline(tp_0,\n",
    "#                         deadline,1.0)\n",
    "#                 if (judge_i != judge_ii):\n",
    "#                     print(\"false\")\n",
    "#                     return\n",
    "                \n",
    "                \n",
    "                if (judge_i == True):\n",
    "                    Possible = Possible + 1.0/len(value_list)\n",
    "\n",
    "            Possible_i_list.append(Possible)\n",
    "\n",
    "        temp_sum_delay_total = torch.zeros(1).cuda()\n",
    "        temp_max_delay_total = torch.zeros(1).cuda()\n",
    "\n",
    "#         print(\"deadline:\",deadline)\n",
    "\n",
    "\n",
    "        for k in range(len(value_list)):\n",
    "            value_tensor = value_list[k]\n",
    "            test = copy.deepcopy(value_tensor)\n",
    "            test_change = copy.deepcopy(test)\n",
    "            test_change = deadline * test_change\n",
    "\n",
    "            temp_sum_delay = 0\n",
    "            temp_max_delay = 0\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                tp_1 = test_change.clone()\n",
    "                tp_1[i] = 1\n",
    "                # tp_0 = copy.deepcopy(test_change_i)\n",
    "                tp_0 = test_change.clone()\n",
    "                tp_0[i] = 0\n",
    "                offer = tpToPayments(tp_1)[i]\n",
    "\n",
    "                Delay_1 = tpToTotalDelay(tp_1, deadline, i)[0]\n",
    "                Delay_2 = tpToTotalDelay(tp_0, deadline, i)[0]\n",
    "\n",
    "                temp = ((1.0 - cdf(offer/deadline[i], order)) * Delay_1 + cdf(\n",
    "                    offer/deadline[i], order) * Delay_2)/Agent_number_n\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "#                 print(\"test_change\",test_change)\n",
    "                \n",
    "#                 print(\"offer\",offer,cdf(offer/deadline[i], order))\n",
    "#                 print(\"temp\",temp)\n",
    "#                 print(\"Delay_1\", Delay_1)\n",
    "#                 print(\"Delay_2\", Delay_2)\n",
    "\n",
    "#                 print()\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "#             print(\"test_change\",test_change)\n",
    "#             print(\"deadline\",deadline)\n",
    "#             print(\"offer\",offer)\n",
    "#             print(\"temp_sum_delay\",temp_sum_delay)\n",
    "\n",
    "#             return\n",
    "\n",
    "            for i in range(Agent_number_n):\n",
    "                Possible = Possible_i_list[i]\n",
    "\n",
    "                temp = (1.0-deadline[i].clone()) * \\\n",
    "                    torch.tensor(1.0-Possible).cuda()\n",
    "                temp_sum_delay = temp_sum_delay + temp\n",
    "\n",
    "            temp_sum_delay_total = temp_sum_delay_total + temp_sum_delay\n",
    "\n",
    "        return temp_max_delay_total, temp_sum_delay_total, deadline.cpu(\n",
    "        ).data.numpy(), float(temp_sum_delay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:31:15.977495Z",
     "start_time": "2021-03-07T05:31:15.969516Z"
    }
   },
   "outputs": [],
   "source": [
    "random.seed(2000)\n",
    "torch.manual_seed(256)\n",
    "net = Net()\n",
    "# net.apply(weight_init)\n",
    "#net = torch.load(\"Deep_learning_with_deadline_5\")\n",
    "net.to(dev)\n",
    "\n",
    "#optimizer = opt.RMSprop(net.parameters(), lr=0.00001)\n",
    "#optimizer = opt.SGD(net.parameters(), lr=0.002)\n",
    "optimizer = opt.Adam(net.parameters(), lr=0.00002)\n",
    "\n",
    "batch_size = 32\n",
    "echo = 1001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:47:57.701370Z",
     "start_time": "2021-03-07T05:31:15.979488Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i 0\n",
      "batch_loss: 1.92 \n",
      "value: [0.768561104246705, 2.009749001138648, -0.12113458701276006, -0.36801741536596483, 2.2097891230117472]\n",
      "deadline: [0.99997115 0.9999707  0.99991417 0.999382   0.9998211 ]\n",
      "\n",
      "i 100\n",
      "batch_loss: 1.64 \n",
      "value: [2.1281031462717097, 0.08802041443790723, 1.2188897252174868, -0.003664706145082679, 0.5825329245897476]\n",
      "deadline: [0.9999677  0.9999714  0.99991715 0.99889815 0.9997677 ]\n",
      "\n",
      "i 200\n",
      "batch_loss: 1.76 \n",
      "value: [-0.07206245519864385, 1.2539247060336085, 1.784232367092181, 1.5717464117374198, 0.7361397986505678]\n",
      "deadline: [0.9999633  0.9999716  0.99992836 0.9972473  0.99966335]\n",
      "\n",
      "i 300\n",
      "batch_loss: 1.92 \n",
      "value: [2.595440852549377, 1.26368289247057, 1.1552250709982659, -0.4196170869829145, 1.1024178618924847]\n",
      "deadline: [0.99995184 0.9999716  0.99994576 0.9881275  0.9993717 ]\n",
      "\n",
      "i 400\n",
      "batch_loss: 1.98 \n",
      "value: [1.675525509008411, -0.08927353505497569, 0.10582815827023256, 1.908605426594495, 2.122497986638227]\n",
      "deadline: [0.99990237 0.9999716  0.99996495 0.8150456  0.99808156]\n",
      "\n",
      "i 500\n",
      "batch_loss: 1.89 \n",
      "value: [0.06665078868846146, 2.652268322469795, -0.2400678753647797, 0.5388776495949554, -0.2709353201834861]\n",
      "deadline: [0.9997453  0.9999585  0.9999782  0.09396643 0.9886165 ]\n",
      "\n",
      "i 600\n",
      "batch_loss: 1.59 \n",
      "value: [-0.15849049477064475, 1.6346102905855433, 1.0125153983427304, 2.027687561989115, 0.29677875464338244]\n",
      "deadline: [0.999405   0.9999205  0.9999832  0.01626014 0.9417956 ]\n",
      "\n",
      "i 700\n",
      "batch_loss: 1.47 \n",
      "value: [0.9252676488504223, 1.3508844545799517, 0.9272643497236003, 0.0942704942430303, -0.1105711268714221]\n",
      "deadline: [0.99855584 0.9998024  0.9999875  0.00490244 0.67023224]\n",
      "\n",
      "i 800\n",
      "batch_loss: 1.72 \n",
      "value: [1.4305536266134042, -1.1187202673007743, 2.206775845239834, 1.2119931251522365, 1.9543280762900042]\n",
      "deadline: [9.9511707e-01 9.9936575e-01 9.9999332e-01 7.8630593e-04 7.4626118e-02]\n",
      "\n",
      "i 900\n",
      "batch_loss: 2.02 \n",
      "value: [1.210332786450295, 1.5715247924403581, -0.5020575439948916, 0.37152477126687494, 2.110866238440441]\n",
      "deadline: [9.8672754e-01 9.9822551e-01 9.9999499e-01 3.4411656e-04 1.9039923e-02]\n",
      "\n",
      "i 1000\n",
      "batch_loss: 2.03 \n",
      "value: [1.4797302619344581, 2.102832874663478, 1.9728037580093292, 2.1891901146935573, 0.8887218574282912]\n",
      "deadline: [9.6457821e-01 9.9432462e-01 9.9999547e-01 2.2848164e-04 1.0086472e-02]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(int(echo)):\n",
    "\n",
    "    # offender_types = []\n",
    "    # defender_types = []\n",
    "    loss_sum = 0\n",
    "    denominator = 0\n",
    "    \"\"\"\n",
    "    for j in range(batch_size):\n",
    "        offender_types.append(random.randint(0, 400))\n",
    "        defender_types.append(random.randint(0, 15))\n",
    "    \"\"\"\n",
    "    X_train_list = []\n",
    "    for j in range(batch_size):\n",
    "        index_random = random.randint(0, len(X_train) - 1)\n",
    "        X_train_list.append(\n",
    "            torch.from_numpy(np.array(X_train[index_random])).cuda().type(torch.float32))\n",
    "        denominator += 1\n",
    "\n",
    "    h_delay_max, h_delay_sum, deadline_R, delay_R = net(X_train_list)\n",
    "    loss_sum += h_delay_sum\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    #loss = torch.square(loss_function(loss_sum / denominator) + 52)\n",
    "    loss = loss_sum / denominator\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if i % 100 == 0:\n",
    "        print(\"i\", i)\n",
    "        print(\"batch_loss: %.2f \" % float(loss_sum / denominator))\n",
    "        print(\"value:\", X_train[index_random])\n",
    "        print(\"deadline:\", deadline_R)\n",
    "        #print(\"delay:\" , delay_R)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:47:57.707352Z",
     "start_time": "2021-03-07T05:47:57.702328Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 2.03 \n",
      "value: [1.4797302619344581, 2.102832874663478, 1.9728037580093292, 2.1891901146935573, 0.8887218574282912]\n",
      "deadline: [9.6457821e-01 9.9432462e-01 9.9999547e-01 2.2848164e-04 1.0086472e-02]\n",
      "delay: 0.7535333037376404\n"
     ]
    }
   ],
   "source": [
    "print(\"batch: %.2f \" % float(loss_sum / denominator))\n",
    "print(\"value:\", X_train[index_random])\n",
    "print(\"deadline:\", deadline_R)\n",
    "print(\"delay:\", delay_R)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:47:59.219734Z",
     "start_time": "2021-03-07T05:47:57.708312Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.756306161060743, 1.6461937982323522)\n"
     ]
    }
   ],
   "source": [
    "def cost_sharing_with_deadline_old(test, t_c, target):\n",
    "    temp_max_delay_list = [0 for i in range(len(test))]\n",
    "    temp_sum_delay = 0\n",
    "    result = False\n",
    "    for k in range(len(test), 0, -1):\n",
    "        count = 0\n",
    "        delay = 0\n",
    "        for ii in range(len(test)):\n",
    "            item = test[ii]\n",
    "            if (item + 1e-4 >= target / k):\n",
    "                count += 1\n",
    "            else:\n",
    "                delay += t_c[ii]\n",
    "                temp_max_delay_list[ii] = t_c[ii]\n",
    "\n",
    "        if (count >= k):\n",
    "            temp_sum_delay += delay\n",
    "            result = True\n",
    "            break\n",
    "        if (k <= 1):\n",
    "            # print(test,number_n);\n",
    "            temp_max_delay_list = t_c\n",
    "            temp_sum_delay = sum(t_c)\n",
    "            result = False\n",
    "\n",
    "    return temp_max_delay_list, temp_sum_delay, result\n",
    "\n",
    "\n",
    "# Cost Sharing\n",
    "def run_cs_old(deadline_list):\n",
    "    sum_delay = 0\n",
    "    max_delay = 0\n",
    "    test_number = 0\n",
    "    for i in range(len(X_test)):\n",
    "        test_number += 1\n",
    "        temp_max_delay = 0\n",
    "        temp_delay = 0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change = []\n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test_change.append(test[j] * deadline_list[j])\n",
    "\n",
    "        temp_max_delay_list, temp_sum_delay, judge1 = cost_sharing_with_deadline_old(\n",
    "            test_change, copy.deepcopy(deadline_list), 1.0)\n",
    "        for j in range(len(test_change)):\n",
    "            test_i = copy.deepcopy(test_change)\n",
    "            test_i = np.delete(test_i, j)\n",
    "\n",
    "            deadline_i = copy.deepcopy(deadline_list)\n",
    "            deadline_i = np.delete(deadline_i, j)\n",
    "\n",
    "            temp_max_delay_i_list, temp_sum_delay_i, judge_i = cost_sharing_with_deadline_old(\n",
    "                test_i, deadline_i, 1.0)\n",
    "\n",
    "            if (judge_i == False):\n",
    "                temp_sum_delay += (1.0 - deadline_list[j])\n",
    "                temp_max_delay_list[j] += (1.0 - deadline_list[j])\n",
    "\n",
    "        max_delay += max(temp_max_delay_list)\n",
    "\n",
    "        sum_delay += temp_sum_delay\n",
    "\n",
    "#     print(\"deadline: \", deadline_list)\n",
    "#     print(\"sum_delay: \", sum_delay / test_number)\n",
    "#     print(\"max_delay: \", max_delay / test_number)\n",
    "#     print()\n",
    "    return max_delay / test_number, sum_delay / test_number\n",
    "\n",
    "\n",
    "print(run_cs_old(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:47:59.225688Z",
     "start_time": "2021-03-07T05:47:59.220665Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(net, \"Deep_learning_with_deadline_3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:47:59.635700Z",
     "start_time": "2021-03-07T05:47:59.227218Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test: (0.7531167202478275, 1.657338618390719)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "class Foo(object):\n",
    "\n",
    "    def __init__(self, test_item, test_change_item, deadline):\n",
    "        self.test_item = test_item\n",
    "        self.test_change_item = test_change_item\n",
    "        self.deadline = deadline\n",
    "\n",
    "    def __lt__(self, other):\n",
    "        return self.test_change_item < other.test_change_item\n",
    "def cost_sharing_with_deadline_free(n,_i,numbers_of_people_will_pay,started_k):\n",
    "    \n",
    "    for k in range(started_k,0,-1):\n",
    "        if(n-_i<=k):\n",
    "            x=k-1\n",
    "        else:\n",
    "            x=k\n",
    "        #print(n,_i,x,numbers_of_people_will_pay[x],k)\n",
    "        if(numbers_of_people_will_pay[x]>=k):\n",
    "            return True,k\n",
    "    return False,0\n",
    "#Cost Sharing\n",
    "def run_cs_test(deadline_list):\n",
    "    sum_delay=0\n",
    "    max_delay=0\n",
    "    test_number=0\n",
    "    seconds_start=time.time()\n",
    "    for i in range(len(X_test)):\n",
    "#        if(i%1000==0):\n",
    "#            seconds=time.time()\n",
    "#            print(\"times: \",seconds-seconds_start)\n",
    "        test_number+=1\n",
    "        temp_max_delay=0\n",
    "        temp_delay=0\n",
    "        test = copy.deepcopy(X_test[i])\n",
    "        #test_change = copy.deepcopy(X_test[i]);\n",
    "        test_change_temp = []\n",
    "        Foo_list = []\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        \n",
    "        for j in range(len(test)):\n",
    "            test_change_temp.append(test[j] * deadline_list[j])\n",
    "            Foo_list.append(Foo(test[j],test_change_temp[j],deadline_list[j]))\n",
    "            \n",
    "        Foo_list.sort(reverse=False)\n",
    "        \n",
    "\n",
    "        for j in range(len(test)):\n",
    "            test[j]=Foo_list[j].test_item\n",
    "            test_change_temp[j]=Foo_list[j].test_change_item\n",
    "            deadline_list[j]=Foo_list[j].deadline\n",
    "\n",
    "        test_change = copy.deepcopy(test_change_temp);\n",
    "        \n",
    "        numbers_of_people_will_pay = [-10 for ii in range(len(test_change)+2)]#pay 1/k\n",
    "        \n",
    "#         seconds=time.time()\n",
    "#         print(\"times: \",seconds-seconds_start)\n",
    "        \n",
    "        k = 1\n",
    "        started=len(test_change)-1\n",
    "        end_k=-10\n",
    "        for j in range(len(test_change)):\n",
    "            if(k<=len(test_change)):\n",
    "                for people_id in range(started,-1,-1):\n",
    "                    if(test_change[people_id]+1e-9>=1.0/k):\n",
    "                        started=people_id\n",
    "                        numbers_of_people_will_pay[k]=len(test_change)-people_id\n",
    "                        end_k=len(test_change)-people_id\n",
    "                    else:\n",
    "                        k+=1\n",
    "                        break;\n",
    "                    \n",
    "        for j in range(k,len(test_change)+1):\n",
    "            numbers_of_people_will_pay[j]=end_k\n",
    "            \n",
    "        deadlist_new=copy.deepcopy(deadline_list)\n",
    "        \n",
    "        temp_max_delay_list,temp_sum_delay,judge_i =  cost_sharing_with_deadline(test_change,\n",
    "                        deadlist_new,1.0)\n",
    "        \n",
    "        judge_i= True\n",
    "        started_k = len(test)\n",
    "        for _i in range(len(test_change)):\n",
    "            if judge_i:\n",
    "                judge_i,started_k =  cost_sharing_with_deadline_free(len(test_change),\n",
    "                    _i,numbers_of_people_will_pay,started_k)\n",
    "                \n",
    "                \n",
    "            started_k+=1\n",
    "            if(judge_i==False):\n",
    "                temp_sum_delay += (1.0-deadline_list[_i])\n",
    "                temp_max_delay_list[_i] += (1.0-deadline_list[_i])\n",
    "        \n",
    "        max_delay+=max(temp_max_delay_list)\n",
    "        \n",
    "        sum_delay+=temp_sum_delay\n",
    "        \n",
    "                \n",
    "    #print(\"max_delay\",max_delay/test_number);\n",
    "                \n",
    "\n",
    "    return max_delay/test_number,sum_delay/test_number\n",
    "\n",
    "    \n",
    "print(\"test:\",run_cs_test(deadline_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:48:26.743161Z",
     "start_time": "2021-03-07T05:47:59.636608Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay: 0.5772700000000397 deadline: 0.51\n",
      "sum_dealy: 1.7495560000000987 deadline: 0.77\n"
     ]
    }
   ],
   "source": [
    "list_1=[]\n",
    "list_2=[]\n",
    "list_3=[]\n",
    "for i in range(1,101):\n",
    "    x=float(i)/100\n",
    "    xx=[x for i in range(Agent_number_n)]\n",
    "    #print(xx)\n",
    "    res1,res2=run_cs_test(xx)\n",
    "    list_1.append(res1)\n",
    "    list_2.append(res2)\n",
    "    list_3.append(x)\n",
    "print(\"max_delay:\",min(list_1),\"deadline:\",list_3[list_1.index(min(list_1))])\n",
    "print(\"sum_dealy:\",min(list_2),\"deadline:\",list_3[list_2.index(min(list_2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:48:28.657103Z",
     "start_time": "2021-03-07T05:48:26.744157Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target: twopeaknormal\n",
      "sum_delay\n",
      "NN: 1.6601738025655766 one_deadline: 1.7495560000000987\n",
      "94.7082%\n"
     ]
    }
   ],
   "source": [
    "print(\"target:\",order)\n",
    "print(\"sum_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[1],\"one_deadline:\",min(list_2))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[1]/min(list_2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-07T05:48:30.573917Z",
     "start_time": "2021-03-07T05:48:28.657835Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_delay\n",
      "NN: 0.7554910493602977 one_deadline: 0.5772700000000397\n",
      "130.4077%\n"
     ]
    }
   ],
   "source": [
    "print(\"max_delay\")\n",
    "print(\"NN:\",run_cs_old(deadline_R)[0],\"one_deadline:\",min(list_1))\n",
    "print(\"{:.4%}\".format(run_cs_test(deadline_R)[0]/min(list_1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "341.4px",
    "left": "535px",
    "right": "20px",
    "top": "92px",
    "width": "351px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
